{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## **size**=**`perc_valid_cf_all`**\n",
    "\n",
    "**Definição do artigo:**\n",
    "- size = |C|/k\n",
    "- Onde |C| = número de counterfactuals válidos gerados\n",
    "- k = número de counterfactuals solicitados\n",
    "\n",
    "**No código:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_valid_cf(cf_list, b, y_val, k=None, y_desidered=None):\n",
    "    n_val = nbr_valid_cf(cf_list, b, y_val, y_desidered)  # |C| - CFs válidos\n",
    "    k = len(cf_list) if k is None else k\n",
    "    res = n_val / k  # |C|/k\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "E na função `evaluate_cf_list` do Guidotti ela vem como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_valid_cf_all_ = perc_valid_cf(cf_list, bb, y_val, k=max_nbr_cf)\n",
    "\n",
    "# Onde `max_nbr_cf` é o k (número de counterfactuals solicitados)\n",
    "# e a função nbr_valid_cf é definida como:\n",
    "def nbr_valid_cf(cf_list, b, y_val, y_desidered=None):\n",
    "    y_cf = b.predict(cf_list)\n",
    "    idx = y_cf != y_val if y_desidered is None else y_cf == y_desidered\n",
    "    val = np.sum(idx)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "**Detalhamento do código:** \n",
    "\n",
    "### `nbr_valid_cf()`\n",
    "1. Faz a predição de todas as instâncias counterfactual (`cf_list`) usando o modelo black box `b`\n",
    "2. Cria um array booleano `idx` que indica quais counterfactuals são válidos\n",
    "3. Se `y_desidered` não é especificado, considera válido qualquer CF com classe diferente da original (`y_cf != y_val`)\n",
    "4. Se `y_desidered` é especificado, considera válido apenas CFs que chegam exatamente naquela classe desejada\n",
    "5. Retorna a contagem total de CFs válidos\n",
    "\n",
    "**Interpretação:**\n",
    "- Um counterfactual é **válido** se, ao ser classificado pelo modelo, produz uma classe diferente da instância original.\n",
    "- **Quanto maior, melhor**\n",
    "- Indica quantos dos CFs gerados realmente funcionam como counterfactuals\n",
    "- Um método perfeito teria `nbr_valid_cf = k` (número de CFs solicitados)\n",
    "- `perc_valid_cf` normaliza isso em porcentagem: valores próximos a 100% são ideais\n",
    "\n",
    "### `perc_valid_cf_all()`\n",
    "\n",
    "**Diferença crucial:**\n",
    "- `perc_valid_cf`: divide pelo número de CFs **efetivamente gerados**\n",
    "- `perc_valid_cf_all`: divide por `k` (número **solicitado** de CFs)\n",
    "\n",
    "---\n",
    "\n",
    "**Resumo:**\n",
    "- `nbr_valid_cf` = |C| (número absoluto de CFs válidos)\n",
    "- `perc_valid_cf` = |C| / |cf_list| (taxa sobre os CFs efetivamente gerados)\n",
    "- **`perc_valid_cf_all` = |C| / k (size do artigo - taxa sobre k solicitados)**\n",
    "\n",
    "Portanto, **`perc_valid_cf_all`** é a métrica \"size\" mencionada no artigo, representando a proporção de counterfactuals válidos em relação ao número k solicitado. Ela ajuda pois alguns métodos podem gerar menos CFs do que o solicitado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## **Actionability**\n",
    "\n",
    "corresponde a **`perc_actionable_cf_all`** no codigo\n",
    "\n",
    "---\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "- $act = |{c ∈ C | a_A(c, x)}| / k$\n",
    "- Onde:\n",
    "  - $|{c ∈ C | a_A(c, x)}|$ = número de counterfactuals que **podem ser realizados** (respeitam constraints)\n",
    "  - $a_A(c, x)$ = função que verifica se o counterfactual c é acionável a partir de x\n",
    "  - $k$ = número de counterfactuals solicitados\n",
    "\n",
    "---\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n",
    "#### **1. Função base: `nbr_actionable_cf`**\n",
    "Conta quantos CFs respeitam os constraints (features imutáveis):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbr_actionable_cf(x, cf_list, variable_features):\n",
    "    nbr_actionable = 0\n",
    "    nbr_features = cf_list.shape[1]\n",
    "    for i, cf in enumerate(cf_list):\n",
    "        constraint_violated = False\n",
    "        for j in range(nbr_features):\n",
    "            # Verifica se uma feature foi alterada E não está na lista de features variáveis\n",
    "            if cf[j] != x[j] and j not in variable_features:\n",
    "                constraint_violated = True\n",
    "                break\n",
    "        if not constraint_violated:\n",
    "            nbr_actionable += 1\n",
    "    return nbr_actionable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Lógica:**\n",
    "- Para cada counterfactual `cf`:\n",
    "  - Verifica todas as features modificadas\n",
    "  - Se alguma feature modificada **NÃO está** em `variable_features` (é imutável), o CF viola constraints\n",
    "  - Conta apenas CFs que **não violam** nenhum constraint\n",
    "\n",
    "#### **2. Função de percentual: `perc_actionable_cf`**\n",
    "Calcula a proporção de CFs acionáveis:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_actionable_cf(x, cf_list, variable_features, k=None):\n",
    "    n_val = nbr_actionable_cf(x, cf_list, variable_features)  # |{c ∈ C | aA(c, x)}|\n",
    "    k = len(cf_list) if k is None else k\n",
    "    res = n_val / k  # Proporção\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **3. Na função `evaluate_cf_list`:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_actionable_cf_all_ = perc_actionable_cf(x, cf_list, variable_features, k=max_nbr_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Onde `max_nbr_cf` é o **k** solicitado.\n",
    "\n",
    "### **Resumo:**\n",
    "- **`nbr_actionable_cf`** = |{c ∈ C | aA(c, x)}| (número absoluto de CFs acionáveis)\n",
    "- **`perc_actionable_cf`** = proporção sobre CFs efetivamente gerados\n",
    "- **`perc_actionable_cf_all`** = **act do artigo** = |{c ∈ C | aA(c, x)}| / k\n",
    "\n",
    "**Exemplo prático:**\n",
    "- Se k=5, técnica gerou 5 CFs, mas apenas 3 respeitam constraints (não modificaram features imutáveis):\n",
    "  - `nbr_actionable_cf` = 3\n",
    "  - `perc_actionable_cf_all` = 3/5 = 0.6 ou 60%\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## **DETALHAMENTO DAS FUNÇÕES E DISTÂNCIAS IMPLEMENTADAS**\n",
    "\n",
    "### **1. Funções de Distância Base**\n",
    "\n",
    "O código implementa múltiplas métricas de distância para acomodar diferentes tipos de dados e necessidades de normalização:\n",
    "\n",
    "#### **1.1. Distâncias para Features Contínuas**\n",
    "\n",
    "**Euclidean Distance (L2)**\n",
    "```python\n",
    "metric='euclidean'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "- Distância padrão no espaço euclidiano: $d(x,y) = \\sqrt{\\sum_{i=1}^{m}(x_i - y_i)^2}$\n",
    "- **Sensível à escala**: features com maior magnitude dominam o cálculo\n",
    "- **Uso**: Quando os dados já estão normalizados ou escala não é problema\n",
    "- **Implementações**: `distance_l2`, `diversity_l2`, `distance_l2j`, `diversity_l2j`\n",
    "\n",
    "**MAD (Median Absolute Deviation)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='mad'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "- **Definição**: MAD mede a dispersão robusta de cada feature\n",
    "  $$MAD_i = \\text{median}(|X_i - \\text{median}(X_i)|)$$\n",
    "- **Normalização**: Cada diferença é dividida pelo MAD da respectiva feature\n",
    "  $$d_{MAD}(x,y) = \\sum_{i=1}^{m}\\frac{|x_i - y_i|}{MAD_i}$$\n",
    "- **Vantagens**:\n",
    "  - Robusto a outliers (usa mediana, não média)\n",
    "  - Normaliza automaticamente diferentes escalas\n",
    "  - Não requer normalização prévia dos dados\n",
    "- **Uso**: **Recomendado** para dados do mundo real com outliers e escalas variadas\n",
    "- **Implementações**: `distance_mad`, `diversity_mad`, `distance_mh`, `diversity_mh`\n",
    "\n",
    "**Implementação no código:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad_cityblock(u, v, mad):\n",
    "    u = _validate_vector(u)\n",
    "    v = _validate_vector(v)\n",
    "    l1_diff = abs(u - v)\n",
    "    l1_diff_mad = l1_diff / mad  # Normalização por MAD\n",
    "    return l1_diff_mad.sum()\n",
    "\n",
    "# Cálculo do MAD\n",
    "mad = median_absolute_deviation(X[:, continuous_features], axis=0)\n",
    "mad = np.array([v if v != 0 else 1.0 for v in mad])  # Evita divisão por zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **1.2. Distâncias para Features Categóricas**\n",
    "\n",
    "**Jaccard Distance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='jaccard'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "- **Definição**: Mede dissimilaridade baseada em conjuntos\n",
    "  $$d_{Jaccard}(x,y) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$$\n",
    "- **Características**:\n",
    "  - Varia entre 0 (idênticos) e 1 (completamente diferentes)\n",
    "  - Considera a presença/ausência de valores\n",
    "  - Apropriado para dados binários ou one-hot encoded\n",
    "- **Uso**: Quando features categóricas são representadas como vetores binários\n",
    "- **Implementações**: `distance_j`, `diversity_j`, `distance_l2j`, `diversity_l2j`\n",
    "\n",
    "**Hamming Distance**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric='hamming'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "- **Definição**: Proporção de features diferentes\n",
    "  $$d_{Hamming}(x,y) = \\frac{1}{m}\\sum_{i=1}^{m}\\mathbb{1}_{x_i \\neq y_i}$$\n",
    "- **Características**:\n",
    "  - Varia entre 0 (idênticos) e 1 (todas as features diferentes)\n",
    "  - Trata cada feature igualmente\n",
    "  - Mais intuitivo para dados categóricos gerais\n",
    "- **Uso**: **Recomendado** para features categóricas nominais\n",
    "- **Implementações**: `distance_h`, `diversity_h`, `distance_mh`, `diversity_mh`\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Distâncias Híbridas (Dados Mistos)**\n",
    "\n",
    "Para datasets com features contínuas **e** categóricas, o código implementa combinações ponderadas:\n",
    "\n",
    "#### **2.1. L2 + Jaccard (distance_l2j / diversity_l2j)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_l2j(x, cf_list, continuous_features, categorical_features, \n",
    "                 ratio_cont=None, agg=None):\n",
    "    dist_cont = continuous_distance(x, cf_list, continuous_features, \n",
    "                                   metric='euclidean', X=None, agg=agg)\n",
    "    dist_cate = categorical_distance(x, cf_list, categorical_features, \n",
    "                                    metric='jaccard', agg=agg)\n",
    "    \n",
    "    # Ponderação proporcional ao número de features\n",
    "    if ratio_cont is None:\n",
    "        ratio_continuous = len(continuous_features) / nbr_features\n",
    "        ratio_categorical = len(categorical_features) / nbr_features\n",
    "    \n",
    "    dist = ratio_continuous * dist_cont + ratio_categorical * dist_cate\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Características:**\n",
    "- Combina Euclidean (contínuas) + Jaccard (categóricas)\n",
    "- Ponderação automática ou manual via `ratio_cont`\n",
    "- **Limitação**: Sensível à escala das contínuas\n",
    "\n",
    "#### **2.2. MAD + Hamming (distance_mh / diversity_mh) - RECOMENDADA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_mh(x, cf_list, continuous_features, categorical_features, \n",
    "                X, ratio_cont=None, agg=None):\n",
    "    dist_cont = continuous_distance(x, cf_list, continuous_features, \n",
    "                                   metric='mad', X=X, agg=agg)\n",
    "    dist_cate = categorical_distance(x, cf_list, categorical_features, \n",
    "                                    metric='hamming', agg=agg)\n",
    "    \n",
    "    dist = ratio_continuous * dist_cont + ratio_categorical * dist_cate\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Vantagens sobre L2J:**\n",
    "- **Robustez**: MAD não é afetado por outliers\n",
    "- **Normalização automática**: Não requer pré-processamento\n",
    "- **Interpretabilidade**: Hamming é mais intuitivo que Jaccard\n",
    "- **Escalabilidade**: Melhor performance em datasets grandes\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Funções de Agregação (agg)**\n",
    "\n",
    "Todas as funções de distância/diversidade suportam agregação:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg=None ou agg='mean'  # Padrão: média aritmética\n",
    "agg='min'               # Mínimo (CF mais próximo/similar)\n",
    "agg='max'               # Máximo (CF mais distante/diverso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Aplicações:**\n",
    "- **Métricas principais** usam `mean` (implementam fórmulas do artigo)\n",
    "- **Métricas auxiliares** usam `min`/`max` para análise detalhada:\n",
    "  - `distance_mh_min`: CF mais próximo (best-case)\n",
    "  - `distance_mh_max`: CF mais distante (worst-case)\n",
    "  - `diversity_mh_min`: Par de CFs mais similar\n",
    "  - `diversity_mh_max`: Par de CFs mais diverso\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Comparação das Implementações**\n",
    "\n",
    "| Métrica | Função Contínuas | Função Categóricas | Normalização | Robustez | Uso Recomendado |\n",
    "|---------|------------------|-------------------|--------------|----------|-----------------|\n",
    "| **distance_l2** | Euclidean | - | Manual | Baixa | Dados normalizados |\n",
    "| **distance_mad** | MAD | - | Automática | Alta | Contínuas com outliers |\n",
    "| **distance_j** | - | Jaccard | N/A | Média | Categóricas binárias |\n",
    "| **distance_h** | - | Hamming | N/A | Alta | Categóricas nominais |\n",
    "| **distance_l2j** | Euclidean | Jaccard | Manual | Baixa | Dados mistos normalizados |\n",
    "| **distance_mh** | MAD | Hamming | Automática | **Alta** | **Dados mistos gerais** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### **Resumo Final:**\n",
    "\n",
    "1. **MAD** é preferível à Euclidean por ser robusta e auto-normalizar\n",
    "2. **Hamming** é mais intuitiva que Jaccard para categóricas gerais\n",
    "3. **distance_mh/diversity_mh** são as implementações **mais robustas** para dados mistos\n",
    "4. Métricas alternativas (l2, l2j) estão disponíveis para **comparação** ou **casos específicos**\n",
    "5. O parâmetro `agg` permite análises **detalhadas** além da média\n",
    "6. Sempre use o **conjunto de treino X** para calcular MAD (consistência)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## **Implausibility** \n",
    "\n",
    "corresponde a função **`plausibility_nbr_cf`**\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "- $impl = (\\frac{1}{|C|})\\sum_{c∈C}{min_{(x∈X)}d(c, x)}$\n",
    "- Onde:\n",
    "  - |C| = número de counterfactuals gerados\n",
    "  - $min_{(x∈X)}d(c, x)$ = distância de cada CF para a instância mais próxima no conjunto de referência X\n",
    "  - Quanto menor, melhor\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n",
    "#### **1. Função base: `plausibility`**\n",
    "Calcula a soma das distâncias de cada CF para a instância mais próxima no conjunto de referência:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plausibility(x, bb, cf_list, X_test, y_pred, continuous_features_all,\n",
    "                 categorical_features_all, X_train, ratio_cont):\n",
    "    sum_dist = 0.0\n",
    "    for cf in cf_list:\n",
    "        # 1. Prediz a classe do counterfactual\n",
    "        y_cf_val = bb.predict(cf.reshape(1, -1))[0]\n",
    "        \n",
    "        # 2. Filtra X_test para instâncias da mesma classe que o CF\n",
    "        X_test_y = X_test[y_cf_val == y_pred]\n",
    "        \n",
    "        # 3. Calcula distâncias e encontra o índice da instância mais próxima\n",
    "        neigh_dist = distance_mh(x.reshape(1, -1), X_test_y, continuous_features_all,\n",
    "                        categorical_features_all, X_train, ratio_cont)\n",
    "        idx_neigh = np.argsort(neigh_dist)[0]\n",
    "        closest = X_test_y[idx_neigh]\n",
    "        \n",
    "        # 4. Calcula distância do CF para a instância mais próxima\n",
    "        d = distance_mh(cf, closest.reshape(1, -1), continuous_features_all,\n",
    "                        categorical_features_all, X_train, ratio_cont)\n",
    "        sum_dist += d\n",
    "    \n",
    "    return sum_dist  # Σ(c∈C) min(x∈X) d(c, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Observação importante:** A implementação busca a instância mais próxima **da mesma classe predita que o CF**, tornando a métrica mais refinada.\n",
    "\n",
    "#### **2. Na função `evaluate_cf_list`:**\n",
    "Várias variações de plausibility são calculadas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plausibility_sum = plausibility(...)  # Soma total\n",
    "\n",
    "# Diferentes normalizações:\n",
    "plausibility_max_nbr_cf_ = plausibility_sum / max_nbr_cf           # Divide por k solicitado\n",
    "plausibility_nbr_cf_ = plausibility_sum / nbr_cf_                  # Divide por CFs gerados\n",
    "plausibility_nbr_valid_cf_ = plausibility_sum / nbr_valid_cf_      # Divide por CFs válidos\n",
    "plausibility_nbr_actionable_cf_ = plausibility_sum / nbr_actionable_cf_\n",
    "plausibility_nbr_valid_actionable_cf_ = plausibility_sum / nbr_valid_actionable_cf_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Resumo:**\n",
    "- **`plausibility_sum`** = $\\sum_{c∈C}{min_{(x∈X)}d(c, x)}$ (soma total)\n",
    "- **`plausibility_nbr_cf`** = **impl do artigo**\n",
    "- Variações alternativas:\n",
    "  - `plausibility_nbr_valid_cf` = normaliza apenas pelos CFs válidos\n",
    "  - `plausibility_max_nbr_cf` = normaliza por k solicitado\n",
    "\n",
    "**Exemplo prático:**\n",
    "- Se gerou 5 CFs e a soma das distâncias mínimas é 10.0:\n",
    "  - `plausibility_sum` = 10.0\n",
    "  - `plausibility_nbr_cf` = 10.0 / 5 = 2.0 (implausibility média)\n",
    "\n",
    "**Interpretação:** Valores baixos indicam que os CFs estão próximos de instâncias reais do conjunto de referência (mais plausíveis). Valores altos indicam CFs distantes da população conhecida (menos plausíveis/mais implausíveis).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Seguindo a definição do artigo, as métricas de **Dissimilarity** correspondem a:\n",
    "\n",
    "## **$dis_{dist}$ (Distance Dissimilarity)**\n",
    "\n",
    "### **Métricas correspondentes no codigo:**\n",
    "- **`distance_mh`** (distancia para dados mistos)\n",
    "- **`distance_l2j`** (alternativa para dados mistos)\n",
    "- **`distance_mad`** (apenas features contínuas)\n",
    "- **`distance_l2`** (apenas features contínuas)\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "- **$dist_{dist} = (\\frac{1}{|C|})\\sum_{x`∈C}{d(x,x`)}$**\n",
    "- Distância média entre x original e cada counterfactual\n",
    "- Quanto menor, melhor (CFs mais próximos ao original)\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mh_ = distance_mh(x, cf_list, continuous_features_all, \n",
    "                          categorical_features_all, X_train, ratio_cont)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A função calcula:\n",
    "1. Distância de `x` para cada `cf` em `cf_list`\n",
    "2. Por padrão (`agg='mean'`), retorna a **média** das distâncias\n",
    "3. Usa MAD para contínuas + Hamming para categóricas\n",
    "\n",
    "**Variações disponíveis:**\n",
    "- `distance_mh_min`: distância mínima (CF mais próximo)\n",
    "- `distance_mh_max`: distância máxima (CF mais distante)\n",
    "\n",
    "---\n",
    "\n",
    "## $dis_{count}$ (Count Dissimilarity)\n",
    "\n",
    "### **Métrica correspondente: `avg_nbr_changes`**\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "- **$dist_{count} = (\\frac{1}{|C|m})\\sum_{c∈C}\\sum_{i=1}^{m}{1_{c_i≠x_i}}$**\n",
    "- o número médio de características alteradas entre um c contrafactual e x\n",
    "- Quanto menor, melhor (menos mudanças necessárias)\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n",
    "#### **1. Função auxiliar: `nbr_changes_per_cf`**\n",
    "Conta quantas features foram alteradas em cada CF:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbr_changes_per_cf(x, cf_list, continuous_features):\n",
    "    nbr_features = cf_list.shape[1]\n",
    "    nbr_changes = np.zeros(len(cf_list))\n",
    "    for i, cf in enumerate(cf_list):\n",
    "        for j in range(nbr_features):\n",
    "            if cf[j] != x[j]:\n",
    "                # Conta 1 para contínua, 0.5 para categórica\n",
    "                nbr_changes[i] += 1 if j in continuous_features else 0.5\n",
    "    return nbr_changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### **2. Função principal: `avg_nbr_changes`**\n",
    "Implementa exatamente a fórmula do artigo:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_nbr_changes(x, cf_list, nbr_features, continuous_features):\n",
    "    val = np.sum(nbr_changes_per_cf(x, cf_list, continuous_features))\n",
    "    nbr_cf, _ = cf_list.shape\n",
    "    return val / (nbr_cf * nbr_features)  # Divide por |C| * m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**No `evaluate_cf_list`:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_nbr_changes_ = avg_nbr_changes(x, cf_list, nbr_features, continuous_features_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "**Interpretação:** Ambas medem **proximidade** - CFs devem ser diferentes o suficiente para mudar a predição, mas próximos o bastante para serem úteis e interpretáveis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## **Diversity** correspondem a:\n",
    "\n",
    "## **1. div_dist (Distance-Based Diversity)**\n",
    "\n",
    "### **Métricas correspondentes:**\n",
    "- **`diversity_mh`** (dados mistos)\n",
    "- **`diversity_l2j`** (alternativa para dados mistos)\n",
    "- **`diversity_mad`** (apenas features contínuas)\n",
    "- **`diversity_l2`** (apenas features contínuas)\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "$$\\text{divdist} = \\frac{1}{|C|^2} \\sum_{c \\in C} \\sum_{c' \\in C} d(c, c')$$\n",
    "\n",
    "- Distância média entre **todos os pares** de counterfactuals\n",
    "- Quanto maior, melhor (CFs mais diversos/diferentes entre si)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_mh(cf_list, continuous_features, categorical_features, X, ratio_cont=None, agg=None):\n",
    "    nbr_features = cf_list.shape[1]\n",
    "    # Diversidade em features contínuas (MAD)\n",
    "    dist_cont = continuous_diversity(cf_list, continuous_features, metric='mad', X=X, agg=agg)\n",
    "    # Diversidade em features categóricas (Hamming)\n",
    "    dist_cate = categorical_diversity(cf_list, categorical_features, metric='hamming', agg=agg)\n",
    "    \n",
    "    # Combinação ponderada\n",
    "    if ratio_cont is None:\n",
    "        ratio_continuous = len(continuous_features) / nbr_features\n",
    "        ratio_categorical = len(categorical_features) / nbr_features\n",
    "    else:\n",
    "        ratio_continuous = ratio_cont\n",
    "        ratio_categorical = 1.0 - ratio_cont\n",
    "    \n",
    "    dist = ratio_continuous * dist_cont + ratio_categorical * dist_cate\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "**Variações disponíveis:**\n",
    "- `diversity_mh_min`: menor distância entre pares (CFs mais similares)\n",
    "- `diversity_mh_max`: maior distância entre pares (CFs mais distantes)\n",
    "\n",
    "---\n",
    "\n",
    "## **2. div_count (Count-Based Diversity)**\n",
    "\n",
    "**Métrica correspondente: `count_diversity_all`**\n",
    "\n",
    "**Definição do Artigo:**\n",
    "$$\\text{divcount} = \\frac{1}{|C|^2 m} \\sum_{c \\in C} \\sum_{c' \\in C} \\sum_{i=1}^{m} \\mathbb{1}_{c_i \\neq c'_i}$$\n",
    "\n",
    "- Proporção média de features diferentes entre pares de CFs\n",
    "- Normalizado por: número de pares × número de features\n",
    "- Quanto maior, melhor (CFs modificam diferentes features)\n",
    "\n",
    "**Como funciona no código:**\n",
    "\n",
    "**1. Função base: `count_diversity`**\n",
    "Implementa a lógica de contagem:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diversity(cf_list, features, nbr_features, continuous_features):\n",
    "    nbr_cf = cf_list.shape[0]\n",
    "    nbr_changes = 0\n",
    "    \n",
    "    # Loop sobre todos os pares (i, j)\n",
    "    for i in range(nbr_cf):\n",
    "        for j in range(i+1, nbr_cf):  # Evita duplicatas\n",
    "            # Para cada feature\n",
    "            for k in features:\n",
    "                if cf_list[i][k] != cf_list[j][k]:\n",
    "                    # Peso: 1 para contínua, 0.5 para categórica\n",
    "                    nbr_changes += 1 if k in continuous_features else 0.5\n",
    "    \n",
    "    # Normalização: divide por |C|² * m\n",
    "    return nbr_changes / (nbr_cf * nbr_cf * nbr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Observação:** O loop usa `range(i+1, nbr_cf)` para contar cada par uma vez, mas a divisão por `nbr_cf * nbr_cf` normaliza considerando todos os pares ordenados, equivalente à fórmula do artigo.\n",
    "\n",
    "#### **2. Função wrapper: `count_diversity_all`**\n",
    "Aplica a todas as features:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_diversity_all(cf_list, nbr_features, continuous_features):\n",
    "    # Aplica count_diversity a TODAS as features\n",
    "    return count_diversity(cf_list, range(cf_list.shape[1]), nbr_features, continuous_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**No `evaluate_cf_list`:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_diversity_all_ = count_diversity_all(cf_list, nbr_features, continuous_features_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Resumo Comparativo:**\n",
    "\n",
    "| Métrica do Artigo | Implementação | Fórmula | Direção |\n",
    "|-------------------|---------------|---------|---------|\n",
    "| **div_dist** | `diversity_mh` | $\\frac{1}{\\|C\\|^2} \\sum_{c \\in C} \\sum_{c' \\in C} d(c, c')$ | ↑ maior melhor |\n",
    "| **div_count** | `count_diversity_all` | $\\frac{1}{\\|C\\|^2 m} \\sum_{c \\in C} \\sum_{c' \\in C} \\sum_{i=1}^{m} \\mathbb{1}_{c_i \\neq c'_i}$ | ↑ maior melhor |\n",
    "\n",
    "**Diferença chave:**\n",
    "- **div_dist**: mede diversidade no **espaço de features** (distância geométrica)\n",
    "- **div_count**: mede diversidade na **contagem de mudanças** (combinatória)\n",
    "\n",
    "**Interpretação:** Alta diversidade significa que o usuário tem múltiplas opções diferentes para reverter a predição negativa, cada uma modificando diferentes combinações de features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "Seguindo a definição do artigo, a métrica de **Discriminative Power** corresponde a:\n",
    "\n",
    "## **Discriminative Power (dipo)**\n",
    "\n",
    "### **Métricas correspondentes:**\n",
    "- **`accuracy_knn_sklearn`** (implementação usando sklearn)\n",
    "- **`accuracy_knn_dist`** (implementação manual com distâncias customizadas)\n",
    "\n",
    "### **Definição do Artigo:**\n",
    "**dipo** = acurácia de um classificador 1-Nearest Neighbor treinado com $C \\cup \\{x\\}$ para classificar instâncias em $X_= \\cup X_{\\neq}$\n",
    "\n",
    "Onde:\n",
    "- $X_= \\subset X$: k instâncias mais próximas de x com $b(X_=) = b(x)$ (mesma classe)\n",
    "- $X_{\\neq} \\subset X$: k instâncias mais próximas de x com $b(X_{\\neq}) \\neq b(x)$ (classe diferente)\n",
    "- Quanto maior, melhor (CFs distinguem bem entre classes)\n",
    "\n",
    "---\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n",
    "#### **1. Função auxiliar: `select_test_knn`**\n",
    "Seleciona o conjunto de teste $X_= \\cup X_{\\neq}$:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_test_knn(x, b, X_test, continuous_features, categorical_features, \n",
    "                    scaler, test_size=5, get_normalized=False):\n",
    "    # Predições\n",
    "    y_val = b.predict(x.reshape(1, -1))\n",
    "    y_test = b.predict(X_test)\n",
    "    \n",
    "    # Normalização\n",
    "    nx = scaler.transform(x.reshape(1, -1))\n",
    "    nX_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Calcular distâncias para X= (mesma classe)\n",
    "    dist_f = euclidean_jaccard(nx, nX_test[y_test == y_val], \n",
    "                               continuous_features, categorical_features)\n",
    "    \n",
    "    # Calcular distâncias para X≠ (classe diferente)\n",
    "    dist_cf = euclidean_jaccard(nx, nX_test[y_test != y_val], \n",
    "                                continuous_features, categorical_features)\n",
    "    \n",
    "    # Selecionar k=test_size instâncias mais próximas de cada classe\n",
    "    index_f = np.argsort(dist_f)[0][:test_size].tolist()   # X=\n",
    "    index_cf = np.argsort(dist_cf)[0][:test_size].tolist() # X≠\n",
    "    \n",
    "    # Combinar: X= ∪ X≠\n",
    "    index = np.array(index_f + index_cf)\n",
    "    \n",
    "    if get_normalized:\n",
    "        return X_test[index], nX_test[index]\n",
    "    return X_test[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Resultado:** Retorna 2×k instâncias (k da mesma classe + k da classe oposta)\n",
    "\n",
    "\n",
    "#### **2. Implementação A: `accuracy_knn_sklearn`**\n",
    "Usa sklearn para treinar e avaliar o 1NN:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_knn_sklearn(x, cf_list, b, X_test, continuous_features, \n",
    "                        categorical_features, scaler, test_size=5):\n",
    "    # 1. Preparar conjunto de treino: C ∪ {x}\n",
    "    clf = KNeighborsClassifier(n_neighbors=1)  # 1-Nearest Neighbor\n",
    "    X_train = np.vstack([x.reshape(1, -1), cf_list])\n",
    "    y_train = b.predict(X_train)\n",
    "    \n",
    "    # 2. Treinar o 1NN\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # 3. Selecionar conjunto de teste: X= ∪ X≠\n",
    "    X_test_knn = select_test_knn(x, b, X_test, continuous_features, \n",
    "                                  categorical_features, scaler, test_size)\n",
    "    \n",
    "    # 4. Obter predições reais e do 1NN\n",
    "    y_test = b.predict(X_test_knn)\n",
    "    y_pred = clf.predict(X_test_knn)\n",
    "    \n",
    "    # 5. Calcular acurácia (discriminative power)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Implementação B: `accuracy_knn_dist`**\n",
    "Implementação manual com cálculo explícito de distâncias:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_knn_dist(x, cf_list, b, X_test, continuous_features, \n",
    "                     categorical_features, scaler, test_size=5):\n",
    "    # 1. Preparar conjunto de treino: C ∪ {x}\n",
    "    X_train = np.vstack([x.reshape(1, -1), cf_list])\n",
    "    y_train = b.predict(X_train)\n",
    "    nX_train = scaler.transform(X_train)\n",
    "    \n",
    "    # 2. Selecionar conjunto de teste: X= ∪ X≠\n",
    "    X_test_knn, nX_test_knn = select_test_knn(x, b, X_test, \n",
    "                                              continuous_features, \n",
    "                                              categorical_features, \n",
    "                                              scaler, test_size, \n",
    "                                              get_normalized=True)\n",
    "    y_test = b.predict(X_test_knn)\n",
    "    \n",
    "    # 3. Classificação manual: para cada instância de teste\n",
    "    y_pred = list()\n",
    "    for nx_test in nX_test_knn:\n",
    "        # Calcular distância para todos no conjunto de treino\n",
    "        dist = euclidean_jaccard(nx_test, nX_train, \n",
    "                                continuous_features, categorical_features)\n",
    "        # Encontrar o vizinho mais próximo (1NN)\n",
    "        idx = np.argmin(dist)\n",
    "        # Atribuir classe do vizinho mais próximo\n",
    "        y_pred.append(y_train[idx])\n",
    "    \n",
    "    # 4. Calcular acurácia (discriminative power)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### **Resumo:**\n",
    "\n",
    "| Métrica do Artigo | Implementação | Descrição | Direção |\n",
    "|-------------------|---------------|-----------|---------|\n",
    "| **dipo** | `accuracy_knn_sklearn` | Acurácia 1NN (sklearn) | ↑ maior melhor |\n",
    "| **dipo** | `accuracy_knn_dist` | Acurácia 1NN (manual) | ↑ maior melhor |\n",
    "\n",
    "**No `evaluate_cf_list`:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_knn_sklearn_ = accuracy_knn_sklearn(x, cf_list, bb, X_test, \n",
    "                                            continuous_features_all,\n",
    "                                            categorical_features_all, \n",
    "                                            scaler, test_size=5)\n",
    "\n",
    "accuracy_knn_dist_ = accuracy_knn_dist(x, cf_list, bb, X_test, \n",
    "                                      continuous_features_all,\n",
    "                                      categorical_features_all, \n",
    "                                      scaler, test_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Interpretação:** \n",
    "- **Alta acurácia (próxima a 1.0)**: Os CFs formam uma boa fronteira de decisão, conseguindo distinguir bem entre as classes\n",
    "- **Baixa acurácia (próxima a 0.5)**: Os CFs não definem bem a fronteira, sugerindo que não são discriminativos ou estão confusos\n",
    "\n",
    "**Por que 1NN?** Pela simplicidade e conexão com o raciocínio humano baseado em exemplos - decisões são tomadas comparando com o caso mais similar conhecido.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## **Runtime**\n",
    "\n",
    "### **Definição:**\n",
    "\n",
    "**Runtime** mede o **tempo decorrido** necessário para o explainer gerar os counterfactuals. É uma métrica de **eficiência computacional**.\n",
    "\n",
    "$$\\text{runtime} = t_{\\text{end}} - t_{\\text{start}}$$\n",
    "\n",
    "Onde:\n",
    "- $t_{\\text{start}}$ = timestamp no início da geração dos CFs\n",
    "- $t_{\\text{end}}$ = timestamp ao final da geração dos CFs\n",
    "- Medido em **segundos**\n",
    "- **Quanto menor, melhor**\n",
    "\n",
    "### **Como funciona no código:**\n",
    "\n",
    "A métrica `runtime` não é calculada dentro de cf_metrics.ipynb, mas sim no **script de experimentos principal** que chama os métodos de geração de counterfactuals. O padrão típico seria:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Antes de gerar CFs\n",
    "time_start = time.time()\n",
    "\n",
    "# Geração dos counterfactuals (chamada ao método)\n",
    "cf_list = explainer.explain(x, k=5)  # Gera k counterfactuals\n",
    "\n",
    "# Após geração\n",
    "time_end = time.time()\n",
    "\n",
    "# Calcula runtime\n",
    "runtime = time_end - time_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Composição no cf_metrics.ipynb:**\n",
    "\n",
    "No arquivo cf_metrics.ipynb, há **três métricas de tempo** nas colunas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [..., 'time_train', 'time_test', 'runtime', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **TABELA RESUMO - MÉTRICAS DE COUNTERFACTUALS**\n",
    "\n",
    "### **Métricas do Artigo de Guidotti**\n",
    "\n",
    "| Métrica | Implementação | Equação | Interpretação | Objetivo |\n",
    "|---------|---------------|---------|-------------|----------|\n",
    "| **Size** | `perc_valid_cf_all` | $\\frac{\\|C\\|}{k}$ | Proporção de CFs válidos gerados | **Maximizar** ↑ |\n",
    "| **Actionability** | `perc_actionable_cf_all` | $\\frac{\\|\\\\{c \\in C \\| a_A(c,x)\\\\}\\|}{k}$ | Proporção de CFs que respeitam constraints | **Maximizar** ↑ |\n",
    "| **Implausibility** | `plausibility_nbr_cf` | $\\frac{1}{\\|C\\|}\\sum_{c\\in C}\\min_{x\\in X}d(c,x)$ | Distância média dos CF para as instâncias mais próximas no conjunto de referência X | **Minimizar** ↓ |\n",
    "| **Dissimilarity_dist** | `distance_mh` | $\\frac{1}{\\|C\\|}\\sum_{c\\in C}d(x,c)$ | Distância média entre x e CFs | **Minimizar** ↓ |\n",
    "| **Dissimilarity_count** | `avg_nbr_changes` | $\\frac{1}{\\|C\\|m}\\sum_{c\\in C}\\sum_{i=1}^{m}\\mathbb{1}_{c_i\\neq x_i}$ | Proporção de features modificadas | **Minimizar** ↓ |\n",
    "| **Diversity_dist** | `diversity_mh` | $\\frac{1}{\\|C\\|^2}\\sum_{c\\in C}\\sum_{c'\\in C}d(c,c')$ | Distância média entre pares de CFs | **Maximizar** ↑ |\n",
    "| **Diversity_count** | `count_diversity_all` | $\\frac{1}{\\|C\\|^2 m}\\sum_{c\\in C}\\sum_{c'\\in C}\\sum_{i=1}^{m}\\mathbb{1}_{c_i\\neq c'_i}$ | Proporção de features diferentes entre CFs | **Maximizar** ↑ |\n",
    "| **Discriminative Power (Dipo)** | `accuracy_knn_sklearn` | Acurácia 1NN em $X_= \\cup X_{\\neq}$ | Capacidade de distinguir entre duas classes diferentes usando apenas os contrafactuais em C | **Maximizar** ↑ |\n",
    "| **Runtime** | `runtime` | $t_{end} - t_{start}$ | Tempo de execução (segundos) | **Minimizar** ↓ |\n",
    "\n",
    "---\n",
    "\n",
    "### **Categorias de Métricas:**\n",
    "\n",
    "#### **1. Validade e Aplicabilidade** (devem ser altas)\n",
    "- **Size**: Garantir que CFs válidos sejam gerados\n",
    "- **Actionability**: Garantir que CFs sejam implementáveis\n",
    "\n",
    "#### **2. Proximidade** (devem ser baixas)\n",
    "- **dis_dist**: CFs próximos ao original (mudanças mínimas)\n",
    "- **dis_count**: Poucas features modificadas (sparsity)\n",
    "- **Implausibility**: CFs próximos a instâncias reais\n",
    "\n",
    "#### **3. Diversidade** (deve ser alta)\n",
    "- **div_dist**: CFs geometricamente diversos\n",
    "- **div_count**: CFs modificam diferentes features\n",
    "\n",
    "#### **4. Qualidade da Explicação** (deve ser alta)\n",
    "- **Discriminative Power**: CFs definem bem a fronteira de decisão\n",
    "\n",
    "#### **5. Robustez** (deve ser baixa)\n",
    "- **Instability**: CFs consistentes sob perturbações\n",
    "\n",
    "#### **6. Eficiência** (deve ser baixa)\n",
    "- **Runtime**: Tempo computacional aceitável\n",
    "\n",
    "---\n",
    "\n",
    "## **Notas Importantes**\n",
    "\n",
    "1. **Normalização**: Todas as métricas de distância dependem da escala dos dados\n",
    "   - `distance_mh` usa MAD (robusto a outliers)\n",
    "   - Valores absolutos variam por dataset\n",
    "\n",
    "2. **Contexto Experimental**:\n",
    "   - Hardware: Ubuntu 20.04, 252GB RAM, Intel i9 3.30GHz × 36\n",
    "   - Runtime deve ser comparado apenas no mesmo hardware\n",
    "\n",
    "3. **Implementações Alternativas**:\n",
    "   - `distance_l2j` vs `distance_mh`: L2+Jaccard vs MAD+Hamming\n",
    "   - `accuracy_knn_sklearn` vs `accuracy_knn_dist`: sklearn vs implementação manual\n",
    "\n",
    "4. **Métricas Complementares**:\n",
    "   - Sempre analisar múltiplas métricas simultaneamente\n",
    "   - Nenhuma métrica isolada captura toda a qualidade dos CFs\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
