{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Reproducibility Notebook: Diabetes Dataset\n",
    "\n",
    "This notebook demonstrates the complete counterfactual generation workflow for the diabetes dataset,\n",
    "comparing DPG and DiCE methods without WandB logging.\n",
    "\n",
    "## Workflow:\n",
    "1. Load and prepare diabetes dataset\n",
    "2. Train Random Forest classifier\n",
    "3. Extract DPG constraints\n",
    "4. Generate counterfactuals using both DPG and DiCE\n",
    "5. Compute and compare metrics\n",
    "6. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure matplotlib for Jupyter\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Add parent directory to path\n",
    "REPO_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "from utils.dataset_loader import load_dataset\n",
    "from utils.config_manager import load_config, DictConfig\n",
    "from utils.replication_runner import run_counterfactual_generation\n",
    "from ConstraintParser import ConstraintParser\n",
    "from CounterFactualMetrics import evaluate_cf_list\n",
    "from CounterFactualVisualizer import (\n",
    "    plot_pca_with_counterfactuals_comparison,\n",
    "    plot_sample_and_counterfactual_heatmap,\n",
    "    heatmap_techniques,\n",
    "    plot_ridge_comparison\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Load Dataset and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes dataset configuration\n",
    "DATASET_NAME = 'diabetes'\n",
    "config_path = REPO_ROOT / 'configs' / DATASET_NAME / 'config.yaml'\n",
    "\n",
    "# Load unified config\n",
    "config = load_config(str(config_path))\n",
    "\n",
    "print(f\"Loaded config for dataset: {DATASET_NAME}\")\n",
    "print(f\"Model type: {config.model.type}\")\n",
    "print(f\"Test size: {config.data.test_size}\")\n",
    "print(f\"Random state: {config.data.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_info = load_dataset(config, repo_root=REPO_ROOT)\n",
    "\n",
    "FEATURES = dataset_info['features']\n",
    "LABELS = dataset_info['labels']\n",
    "FEATURE_NAMES = dataset_info['feature_names']\n",
    "FEATURES_DF = dataset_info['features_df']\n",
    "\n",
    "print(f\"Dataset shape: {FEATURES.shape}\")\n",
    "print(f\"Number of features: {len(FEATURE_NAMES)}\")\n",
    "print(f\"Feature names: {FEATURE_NAMES}\")\n",
    "print(f\"Class distribution: {np.bincount(LABELS)}\")\n",
    "\n",
    "# Display first few samples\n",
    "print(\"\\nFirst 5 samples:\")\n",
    "display(pd.DataFrame(FEATURES[:5], columns=FEATURE_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "TRAIN_FEATURES, TEST_FEATURES, TRAIN_LABELS, TEST_LABELS = train_test_split(\n",
    "    FEATURES_DF,\n",
    "    LABELS,\n",
    "    test_size=config.data.test_size,\n",
    "    random_state=config.data.random_state\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(TRAIN_FEATURES)}\")\n",
    "print(f\"Test samples: {len(TEST_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "model_config = config.model.to_dict() if hasattr(config.model, 'to_dict') else dict(config.model)\n",
    "model_params = {k: v for k, v in model_config.items() if k != 'type' and v is not None}\n",
    "\n",
    "model = RandomForestClassifier(**model_params)\n",
    "model.fit(TRAIN_FEATURES, TRAIN_LABELS)\n",
    "\n",
    "# Evaluate model\n",
    "train_score = model.score(TRAIN_FEATURES, TRAIN_LABELS)\n",
    "test_score = model.score(TEST_FEATURES, TEST_LABELS)\n",
    "\n",
    "print(f\"✓ Model trained successfully\")\n",
    "print(f\"Train accuracy: {train_score:.4f}\")\n",
    "print(f\"Test accuracy: {test_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3. Extract DPG Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DPG constraints from training data\n",
    "import time\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "dpg_result = ConstraintParser.extract_constraints_from_dataset(\n",
    "    model,\n",
    "    TRAIN_FEATURES.values,\n",
    "    TRAIN_LABELS,\n",
    "    FEATURE_NAMES,\n",
    "    dpg_config=None  # Use default DPG config\n",
    ")\n",
    "\n",
    "constraints = dpg_result['constraints']\n",
    "normalized_constraints = ConstraintParser.normalize_constraints(constraints)\n",
    "\n",
    "extraction_time = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"✓ DPG constraints extracted in {extraction_time:.3f}s\")\n",
    "print(f\"Number of features with constraints: {len(constraints)}\")\n",
    "\n",
    "# Display constraints for first few features\n",
    "print(\"\\nSample constraints (first 3 features):\")\n",
    "for i, feature in enumerate(FEATURE_NAMES[:3]):\n",
    "    if feature in normalized_constraints:\n",
    "        print(f\"  {feature}: {normalized_constraints[feature]}\")\n",
    "\n",
    "# Visualize constraints\n",
    "print(\"\\nConstraints visualization:\")\n",
    "from CounterFactualVisualizer import plot_constraints\n",
    "\n",
    "plot_constraints(\n",
    "    constraints=constraints,\n",
    "    overlapping=True,\n",
    "    class_colors_list=['purple', 'green', 'orange']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Select Sample and Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample from training set for counterfactual generation\n",
    "SAMPLE_INDEX = 0  # Use first sample\n",
    "\n",
    "original_sample_values = TRAIN_FEATURES.iloc[SAMPLE_INDEX].values\n",
    "ORIGINAL_SAMPLE = dict(zip(FEATURE_NAMES, map(float, original_sample_values)))\n",
    "SAMPLE_DATAFRAME = pd.DataFrame([ORIGINAL_SAMPLE])\n",
    "ORIGINAL_CLASS = int(model.predict(SAMPLE_DATAFRAME)[0])\n",
    "\n",
    "# Select target class (opposite of original)\n",
    "unique_classes = np.unique(LABELS)\n",
    "TARGET_CLASS = [c for c in unique_classes if c != ORIGINAL_CLASS][0]\n",
    "\n",
    "print(f\"Sample index: {SAMPLE_INDEX}\")\n",
    "print(f\"Original class: {ORIGINAL_CLASS}\")\n",
    "print(f\"Target class: {TARGET_CLASS}\")\n",
    "print(f\"\\nOriginal sample values:\")\n",
    "display(SAMPLE_DATAFRAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build actionability constraints from config\n",
    "from utils.config_manager import build_dict_non_actionable\n",
    "\n",
    "CONTINUOUS_INDICES = dataset_info.get('continuous_indices', list(range(len(FEATURE_NAMES))))\n",
    "CATEGORICAL_INDICES = dataset_info.get('categorical_indices', [])\n",
    "VARIABLE_INDICES = dataset_info.get('variable_indices', list(range(len(FEATURE_NAMES))))\n",
    "\n",
    "dict_non_actionable = build_dict_non_actionable(config, FEATURE_NAMES, VARIABLE_INDICES)\n",
    "\n",
    "print(\"Actionability constraints:\")\n",
    "frozen_features = [f for f, rule in dict_non_actionable.items() if rule == 'no_change']\n",
    "directional_features = {f: rule for f, rule in dict_non_actionable.items() \n",
    "                       if rule in ['non_increasing', 'non_decreasing']}\n",
    "\n",
    "if frozen_features:\n",
    "    print(f\"  Frozen features: {frozen_features}\")\n",
    "if directional_features:\n",
    "    print(f\"  Directional constraints: {directional_features}\")\n",
    "if not frozen_features and not directional_features:\n",
    "    print(\"  All features actionable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 5. Generate Counterfactuals - DPG Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for DPG method\n",
    "config_dpg = config.to_dict()\n",
    "config_dpg['counterfactual']['method'] = 'dpg'\n",
    "\n",
    "# Prepare training data for DiCE (not used for DPG but required by interface)\n",
    "train_df_for_dice = TRAIN_FEATURES.copy()\n",
    "train_df_for_dice['_target_'] = TRAIN_LABELS\n",
    "\n",
    "# Generate DPG counterfactuals\n",
    "NUM_CFS = 5\n",
    "config_dpg['experiment_params']['requested_counterfactuals'] = NUM_CFS\n",
    "\n",
    "generation_args_dpg = (\n",
    "    ORIGINAL_SAMPLE,\n",
    "    TARGET_CLASS,\n",
    "    FEATURE_NAMES,\n",
    "    dict_non_actionable,\n",
    "    config_dpg,\n",
    "    model,\n",
    "    constraints,\n",
    "    train_df_for_dice,\n",
    "    CONTINUOUS_INDICES,\n",
    "    CATEGORICAL_INDICES\n",
    ")\n",
    "\n",
    "print(f\"Generating {NUM_CFS} counterfactuals using DPG...\")\n",
    "start_time = time.perf_counter()\n",
    "result_dpg = run_counterfactual_generation(generation_args_dpg)\n",
    "dpg_runtime = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"✓ DPG generation completed in {dpg_runtime:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DPG counterfactuals\n",
    "dpg_counterfactuals = result_dpg.get('all_counterfactuals', [])\n",
    "dpg_cf_df = pd.DataFrame(dpg_counterfactuals)\n",
    "dpg_predictions = model.predict(dpg_cf_df) if len(dpg_counterfactuals) > 0 else []\n",
    "\n",
    "# Count valid (matching target class)\n",
    "dpg_valid = sum(1 for pred in dpg_predictions if pred == TARGET_CLASS)\n",
    "\n",
    "print(f\"DPG Results:\")\n",
    "print(f\"  Generated: {len(dpg_counterfactuals)} counterfactuals\")\n",
    "print(f\"  Valid (target class): {dpg_valid}/{len(dpg_counterfactuals)}\")\n",
    "print(f\"  Success rate: {dpg_valid/NUM_CFS*100:.1f}%\")\n",
    "\n",
    "if len(dpg_counterfactuals) > 0:\n",
    "    print(f\"\\nFirst DPG counterfactual:\")\n",
    "    display(pd.DataFrame([dpg_counterfactuals[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 6. Generate Counterfactuals - DiCE Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure for DiCE method\n",
    "config_dice = config.to_dict()\n",
    "config_dice['counterfactual']['method'] = 'dice'\n",
    "config_dice['experiment_params']['requested_counterfactuals'] = NUM_CFS\n",
    "\n",
    "generation_args_dice = (\n",
    "    ORIGINAL_SAMPLE,\n",
    "    TARGET_CLASS,\n",
    "    FEATURE_NAMES,\n",
    "    dict_non_actionable,\n",
    "    config_dice,\n",
    "    model,\n",
    "    constraints,\n",
    "    train_df_for_dice,\n",
    "    CONTINUOUS_INDICES,\n",
    "    CATEGORICAL_INDICES\n",
    ")\n",
    "\n",
    "print(f\"Generating {NUM_CFS} counterfactuals using DiCE...\")\n",
    "start_time = time.perf_counter()\n",
    "result_dice = run_counterfactual_generation(generation_args_dice)\n",
    "dice_runtime = time.perf_counter() - start_time\n",
    "\n",
    "print(f\"✓ DiCE generation completed in {dice_runtime:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract DiCE counterfactuals\n",
    "dice_counterfactuals = result_dice.get('all_counterfactuals', [])\n",
    "dice_cf_df = pd.DataFrame(dice_counterfactuals)\n",
    "dice_predictions = model.predict(dice_cf_df) if len(dice_counterfactuals) > 0 else []\n",
    "\n",
    "# Count valid\n",
    "dice_valid = sum(1 for pred in dice_predictions if pred == TARGET_CLASS)\n",
    "\n",
    "print(f\"DiCE Results:\")\n",
    "print(f\"  Generated: {len(dice_counterfactuals)} counterfactuals\")\n",
    "print(f\"  Valid (target class): {dice_valid}/{len(dice_counterfactuals)}\")\n",
    "print(f\"  Success rate: {dice_valid/NUM_CFS*100:.1f}%\")\n",
    "\n",
    "if len(dice_counterfactuals) > 0:\n",
    "    print(f\"\\nFirst DiCE counterfactual:\")\n",
    "    display(pd.DataFrame([dice_counterfactuals[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 7. Compute and Compare Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute comprehensive metrics for both methods\n",
    "x_original = np.array([ORIGINAL_SAMPLE[feat] for feat in FEATURE_NAMES])\n",
    "X_train = TRAIN_FEATURES.values\n",
    "X_test = TEST_FEATURES.values\n",
    "\n",
    "# DPG metrics\n",
    "if len(dpg_counterfactuals) > 0:\n",
    "    dpg_cf_array = np.array([[cf[feat] for feat in FEATURE_NAMES] for cf in dpg_counterfactuals])\n",
    "    dpg_metrics = evaluate_cf_list(\n",
    "        cf_list=dpg_cf_array,  # Pass numpy array directly, not list\n",
    "        x=x_original,\n",
    "        model=model,\n",
    "        y_val=ORIGINAL_CLASS,\n",
    "        max_nbr_cf=NUM_CFS,\n",
    "        variable_features=VARIABLE_INDICES,\n",
    "        continuous_features_all=CONTINUOUS_INDICES,\n",
    "        categorical_features_all=CATEGORICAL_INDICES,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        ratio_cont=len(CONTINUOUS_INDICES)/len(FEATURE_NAMES),\n",
    "        nbr_features=len(FEATURE_NAMES)\n",
    "    )\n",
    "else:\n",
    "    dpg_metrics = {}\n",
    "\n",
    "# DiCE metrics\n",
    "if len(dice_counterfactuals) > 0:\n",
    "    dice_cf_array = np.array([[cf[feat] for feat in FEATURE_NAMES] for cf in dice_counterfactuals])\n",
    "    dice_metrics = evaluate_cf_list(\n",
    "        cf_list=dice_cf_array,  # Pass numpy array directly, not list\n",
    "        x=x_original,\n",
    "        model=model,\n",
    "        y_val=ORIGINAL_CLASS,\n",
    "        max_nbr_cf=NUM_CFS,\n",
    "        variable_features=VARIABLE_INDICES,\n",
    "        continuous_features_all=CONTINUOUS_INDICES,\n",
    "        categorical_features_all=CATEGORICAL_INDICES,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        ratio_cont=len(CONTINUOUS_INDICES)/len(FEATURE_NAMES),\n",
    "        nbr_features=len(FEATURE_NAMES)\n",
    "    )\n",
    "else:\n",
    "    dice_metrics = {}\n",
    "\n",
    "print(\"✓ Metrics computed for both methods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "key_metrics = [\n",
    "    'perc_valid_cf_all',\n",
    "    'perc_actionable_cf_all',\n",
    "    'plausibility_nbr_cf',\n",
    "    'distance_mh',\n",
    "    'avg_nbr_changes',\n",
    "    'count_diversity_all',\n",
    "    'accuracy_knn_sklearn'\n",
    "]\n",
    "\n",
    "comparison_data = []\n",
    "for metric in key_metrics:\n",
    "    dpg_val = dpg_metrics.get(metric, 'N/A')\n",
    "    dice_val = dice_metrics.get(metric, 'N/A')\n",
    "    \n",
    "    # Format values\n",
    "    if dpg_val != 'N/A':\n",
    "        dpg_val = f\"{dpg_val:.4f}\" if isinstance(dpg_val, (int, float)) else dpg_val\n",
    "    if dice_val != 'N/A':\n",
    "        dice_val = f\"{dice_val:.4f}\" if isinstance(dice_val, (int, float)) else dice_val\n",
    "    \n",
    "    comparison_data.append({\n",
    "        'Metric': metric,\n",
    "        'DPG': dpg_val,\n",
    "        'DiCE': dice_val\n",
    "    })\n",
    "\n",
    "# Add runtime\n",
    "comparison_data.append({\n",
    "    'Metric': 'runtime',\n",
    "    'DPG': f\"{dpg_runtime:.3f}s\",\n",
    "    'DiCE': f\"{dice_runtime:.3f}s\"\n",
    "})\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Comparison Plot\n",
    "if len(dpg_counterfactuals) > 0 and len(dice_counterfactuals) > 0:\n",
    "    from IPython.display import Image, display\n",
    "    import io\n",
    "    \n",
    "    # Prepare DataFrames and predictions\n",
    "    dpg_cf_df_viz = pd.DataFrame(dpg_counterfactuals)\n",
    "    dice_cf_df_viz = pd.DataFrame(dice_counterfactuals)\n",
    "    dpg_preds_viz = model.predict(dpg_cf_df_viz)\n",
    "    dice_preds_viz = model.predict(dice_cf_df_viz)\n",
    "    \n",
    "    fig = plot_pca_with_counterfactuals_comparison(\n",
    "        model=model,\n",
    "        dataset=FEATURES_DF,\n",
    "        target=LABELS,\n",
    "        sample=ORIGINAL_SAMPLE,\n",
    "        counterfactuals_df_1=dpg_cf_df_viz,\n",
    "        cf_predicted_classes_1=dpg_preds_viz,\n",
    "        counterfactuals_df_2=dice_cf_df_viz,\n",
    "        cf_predicted_classes_2=dice_preds_viz,\n",
    "        method_1_name='DPG',\n",
    "        method_2_name='DiCE',\n",
    "        method_1_color=\"#CC0000\",\n",
    "        method_2_color=\"#006DAC\"\n",
    "    )\n",
    "    \n",
    "    # Save to BytesIO and display (figures are closed by the function)\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    display(Image(buf.read()))\n",
    "    buf.close()\n",
    "else:\n",
    "    print(\"Insufficient counterfactuals for PCA plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Heatmap Comparison\n",
    "if len(dpg_counterfactuals) > 0 and len(dice_counterfactuals) > 0:\n",
    "    from IPython.display import Image, display\n",
    "    import io\n",
    "    \n",
    "    # Take first 5 counterfactuals from each method\n",
    "    n_display = min(5, len(dpg_counterfactuals), len(dice_counterfactuals))\n",
    "    \n",
    "    fig = heatmap_techniques(\n",
    "        sample=ORIGINAL_SAMPLE,\n",
    "        class_sample=ORIGINAL_CLASS,\n",
    "        cf_list_1=dpg_counterfactuals[:n_display],\n",
    "        cf_list_2=dice_counterfactuals[:n_display],\n",
    "        technique_names=('DPG', 'DiCE'),\n",
    "        restrictions=dict_non_actionable\n",
    "    )\n",
    "    \n",
    "    # Save to BytesIO and display\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    display(Image(buf.read()))\n",
    "    buf.close()\n",
    "else:\n",
    "    print(\"Insufficient counterfactuals for heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Plot - Feature Distribution Comparison\n",
    "if len(dpg_counterfactuals) >= 2 and len(dice_counterfactuals) >= 2:\n",
    "    from IPython.display import Image, display\n",
    "    import io\n",
    "    \n",
    "    try:\n",
    "        fig = plot_ridge_comparison(\n",
    "            sample=ORIGINAL_SAMPLE,\n",
    "            cf_list_1=dpg_counterfactuals,\n",
    "            cf_list_2=dice_counterfactuals,\n",
    "            technique_names=('DPG', 'DiCE'),\n",
    "            dataset_df=FEATURES_DF,\n",
    "            constraints=normalized_constraints,\n",
    "            target_class=TARGET_CLASS\n",
    "        )\n",
    "        \n",
    "        # Save to BytesIO and display\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        display(Image(buf.read()))\n",
    "        buf.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create ridge plot: {e}\")\n",
    "else:\n",
    "    print(\"Need at least 2 counterfactuals from each method for ridge plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### DPG Constraints Visualization\n",
    "\n",
    "This plot shows the DPG-learned constraints (min/max bounds per feature per class) with the original sample and first counterfactuals from both methods overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPG Constraints Overview with Counterfactuals\n",
    "if len(dpg_counterfactuals) > 0 and len(dice_counterfactuals) > 0:\n",
    "    from IPython.display import Image, display\n",
    "    import io\n",
    "    from DPG.dpg import plot_dpg_constraints_overview\n",
    "    from matplotlib.lines import Line2D\n",
    "    \n",
    "    try:\n",
    "        # Get first CF from each method\n",
    "        dpg_first_cf = dpg_counterfactuals[0]\n",
    "        dice_first_cf = dice_counterfactuals[0]\n",
    "        \n",
    "        # Define class colors\n",
    "        class_colors_list = ['purple', 'green', 'orange']\n",
    "        \n",
    "        # Create base constraints plot\n",
    "        fig = plot_dpg_constraints_overview(\n",
    "            normalized_constraints=normalized_constraints,\n",
    "            feature_names=FEATURE_NAMES,\n",
    "            class_colors_list=class_colors_list,\n",
    "            original_sample=ORIGINAL_SAMPLE,\n",
    "            original_class=ORIGINAL_CLASS,\n",
    "            target_class=TARGET_CLASS,\n",
    "            title=f\"{DATASET_NAME}: DPG Constraints with First Counterfactuals\"\n",
    "        )\n",
    "        \n",
    "        if fig is None:\n",
    "            print(\"Could not create constraints visualization\")\n",
    "        else:\n",
    "            # Get the axis from the figure\n",
    "            ax = fig.axes[0]\n",
    "            \n",
    "            # Get features with constraints and their y positions\n",
    "            features_with_constraints = []\n",
    "            for feat in FEATURE_NAMES:\n",
    "                has_constraint = any(\n",
    "                    feat in normalized_constraints.get(cname, {})\n",
    "                    for cname in normalized_constraints.keys()\n",
    "                )\n",
    "                if has_constraint:\n",
    "                    features_with_constraints.append(feat)\n",
    "            \n",
    "            n_features = len(features_with_constraints)\n",
    "            y_positions = np.arange(n_features)\n",
    "            feature_to_y = {feat: y_positions[i] for i, feat in enumerate(features_with_constraints)}\n",
    "            \n",
    "            # Define colors matching PCA comparison\n",
    "            dpg_color = \"#CC0000\"  # Red/Orange for DPG\n",
    "            dice_color = \"#006DAC\"  # Blue for DiCE\n",
    "            marker_size = 150\n",
    "            linewidth = 2.5\n",
    "            \n",
    "            # Overlay DPG counterfactual markers (triangle down)\n",
    "            for feat in features_with_constraints:\n",
    "                if feat in dpg_first_cf and feat in feature_to_y:\n",
    "                    y = feature_to_y[feat]\n",
    "                    x = dpg_first_cf[feat]\n",
    "                    ax.scatter(x, y, marker='v', s=marker_size,\n",
    "                              edgecolor=dpg_color, facecolor='none',\n",
    "                              linewidths=linewidth, zorder=10)\n",
    "            \n",
    "            # Overlay DiCE counterfactual markers (square)\n",
    "            for feat in features_with_constraints:\n",
    "                if feat in dice_first_cf and feat in feature_to_y:\n",
    "                    y = feature_to_y[feat]\n",
    "                    x = dice_first_cf[feat]\n",
    "                    ax.scatter(x, y, marker='s', s=marker_size,\n",
    "                              edgecolor=dice_color, facecolor='none',\n",
    "                              linewidths=linewidth, zorder=10)\n",
    "            \n",
    "            # Add enhanced legend\n",
    "            legend_elements = [\n",
    "                Line2D([0], [0], marker='o', color='w',\n",
    "                       markerfacecolor='black', markersize=12,\n",
    "                       markeredgecolor='black', markeredgewidth=linewidth,\n",
    "                       label='Original Sample'),\n",
    "                Line2D([0], [0], marker='v', color='w',\n",
    "                       markerfacecolor='none', markersize=12,\n",
    "                       markeredgecolor=dpg_color, markeredgewidth=linewidth,\n",
    "                       label='DPG CF #1'),\n",
    "                Line2D([0], [0], marker='s', color='w',\n",
    "                       markerfacecolor='none', markersize=12,\n",
    "                       markeredgecolor=dice_color, markeredgewidth=linewidth,\n",
    "                       label='DiCE CF #1')\n",
    "            ]\n",
    "            ax.legend(handles=legend_elements, loc='upper right', fontsize=10)\n",
    "            \n",
    "            # Display the figure\n",
    "            buf = io.BytesIO()\n",
    "            fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "            buf.seek(0)\n",
    "            display(Image(buf.read()))\n",
    "            buf.close()\n",
    "            plt.close(fig)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Could not create constraints visualization: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"Insufficient counterfactuals for constraints visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Counterfactual Comparison (first CF from each method)\n",
    "if len(dpg_counterfactuals) > 0 and len(dice_counterfactuals) > 0:\n",
    "    from IPython.display import Image, display\n",
    "    import io\n",
    "    \n",
    "    sample_df = pd.DataFrame([ORIGINAL_SAMPLE])\n",
    "    \n",
    "    try:\n",
    "        fig = plot_sample_and_counterfactual_comparison_combined(\n",
    "            model=model,\n",
    "            sample=ORIGINAL_SAMPLE,\n",
    "            sample_df=sample_df,\n",
    "            dpg_cf=dpg_counterfactuals[0],\n",
    "            dice_cf=dice_counterfactuals[0],\n",
    "            method_names=('DPG', 'DiCE'),\n",
    "            constraints=normalized_constraints,\n",
    "            restrictions=dict_non_actionable\n",
    "        )\n",
    "        \n",
    "        # Save to BytesIO and display\n",
    "        buf = io.BytesIO()\n",
    "        fig.savefig(buf, format='png', dpi=100, bbox_inches='tight')\n",
    "        buf.seek(0)\n",
    "        display(Image(buf.read()))\n",
    "        buf.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not create combined comparison plot: {e}\")\n",
    "else:\n",
    "    print(\"Insufficient counterfactuals for individual comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook demonstrated the complete workflow for counterfactual generation on the diabetes dataset:\n",
    "- Both DPG and DiCE methods were applied\n",
    "- Metrics were computed and compared\n",
    "- Multiple visualizations show the differences between methods\n",
    "\n",
    "Key observations can be made from the metrics comparison table and visualizations above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"REPRODUCIBILITY SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Dataset: {DATASET_NAME}\")\n",
    "print(f\"Sample index: {SAMPLE_INDEX}\")\n",
    "print(f\"Original class: {ORIGINAL_CLASS} → Target class: {TARGET_CLASS}\")\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Train accuracy: {train_score:.4f}\")\n",
    "print(f\"  Test accuracy: {test_score:.4f}\")\n",
    "print(f\"\\nDPG Results:\")\n",
    "print(f\"  Valid CFs: {dpg_valid}/{NUM_CFS} ({dpg_valid/NUM_CFS*100:.1f}%)\")\n",
    "print(f\"  Runtime: {dpg_runtime:.3f}s\")\n",
    "print(f\"\\nDiCE Results:\")\n",
    "print(f\"  Valid CFs: {dice_valid}/{NUM_CFS} ({dice_valid/NUM_CFS*100:.1f}%)\")\n",
    "print(f\"  Runtime: {dice_runtime:.3f}s\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
