{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CounterFactual Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import Bunch\n",
    "from typing import cast\n",
    "from CounterFactualModel import CounterFactualModel\n",
    "from ConstraintParser import ConstraintParser\n",
    "import CounterFactualVisualizer as CounterFactualVisualizer\n",
    "importlib.reload(CounterFactualVisualizer)\n",
    "from CounterFactualVisualizer import (plot_pca_with_counterfactual, plot_sample_and_counterfactual_heatmap, \n",
    "                                     plot_pca_loadings, plot_constraints, \n",
    "                                     plot_sample_and_counterfactual_comparison, plot_pairwise_with_counterfactual_df,\n",
    "                                     plot_pca_with_counterfactuals, plot_explainer_summary)\n",
    "from CounterFactualExplainer import CounterFactualExplainer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline display and create helper function\n",
    "%matplotlib inline\n",
    "\n",
    "def display_figure(fig):\n",
    "    \"\"\"Helper function to properly display matplotlib figures loaded from pickle\"\"\"\n",
    "    if fig is not None:\n",
    "        # For matplotlib figures, we need to explicitly show them\n",
    "        if hasattr(fig, 'canvas'):\n",
    "            from IPython.display import display\n",
    "            display(fig)\n",
    "            # Force render\n",
    "            fig.canvas.draw()\n",
    "        else:\n",
    "            display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage helpers using the per-sample layout (delegates to utils.notebooks.experiment_storage)\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory for storing experiment results (kept for compatibility)\n",
    "OUTPUT_DIR = \"experiment_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "from utils.notebooks.experiment_storage import (\n",
    "    list_available_samples as storage_list_available_samples,\n",
    "    load_visualizations_data as storage_load_visualizations_data,\n",
    ")\n",
    "\n",
    "class LazyVisualizationLoader:\n",
    "    \"\"\"Lazy loader for visualization data - loads only what's needed when needed.\n",
    "\n",
    "    This loader looks for files under:\n",
    "        experiment_results/<sample_id>/after_viz_generation.pkl\n",
    "    and falls back to older flat filenames when present.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sample_id, output_dir=OUTPUT_DIR):\n",
    "        self.sample_id = sample_id\n",
    "        self.output_dir = output_dir\n",
    "        self._metadata = None\n",
    "        self._full_data = None\n",
    "        self._loaded_combinations = {}\n",
    "\n",
    "    def _ensure_loaded(self):\n",
    "        if self._full_data is None:\n",
    "            # Use the central storage loader which already handles fallbacks\n",
    "            self._full_data = storage_load_visualizations_data(self.sample_id, self.output_dir)\n",
    "\n",
    "    def load_metadata(self):\n",
    "        \"\"\"Load only the metadata (fast - no visualizations)\"\"\"\n",
    "        if self._metadata is not None:\n",
    "            return self._metadata\n",
    "\n",
    "        self._ensure_loaded()\n",
    "        data = self._full_data\n",
    "\n",
    "        self._metadata = {\n",
    "            'sample_id': data['sample_id'],\n",
    "            'original_sample': data.get('original_sample'),\n",
    "            'constraints': data.get('constraints', {}),\n",
    "            'features_names': data.get('features_names', []),\n",
    "            'target_class': data.get('target_class'),\n",
    "            'num_combinations': len(data.get('visualizations', [])),\n",
    "            'combination_labels': [viz.get('label') for viz in data.get('visualizations', [])],\n",
    "            'combination_replication_counts': [len(viz.get('replication', [])) for viz in data.get('visualizations', [])]\n",
    "        }\n",
    "\n",
    "        return self._metadata\n",
    "\n",
    "    def get_combination_data(self, combination_idx):\n",
    "        \"\"\"Load specific combination data on-demand\"\"\"\n",
    "        if combination_idx in self._loaded_combinations:\n",
    "            return self._loaded_combinations[combination_idx]\n",
    "\n",
    "        self._ensure_loaded()\n",
    "\n",
    "        try:\n",
    "            combo_data = self._full_data['visualizations'][combination_idx]\n",
    "        except Exception as e:\n",
    "            raise IndexError(f\"Combination {combination_idx} not found for sample {self.sample_id}\") from e\n",
    "\n",
    "        self._loaded_combinations[combination_idx] = combo_data\n",
    "        return combo_data\n",
    "\n",
    "\n",
    "def load_visualizations_data_lazy(sample_id):\n",
    "    \"\"\"Create a lazy loader for the sample\"\"\"\n",
    "    loader = LazyVisualizationLoader(sample_id)\n",
    "    loader.load_metadata()\n",
    "    return loader\n",
    "\n",
    "\n",
    "def list_available_samples():\n",
    "    \"\"\"List all available samples using the central storage helper.\"\"\"\n",
    "    return storage_list_available_samples(OUTPUT_DIR)\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Available samples: {len(list_available_samples())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Setup + Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_COLORS_LIST = ['purple', 'green', 'orange']\n",
    "IRIS: Bunch = cast(Bunch, load_iris())\n",
    "IRIS_FEATURES = IRIS.data\n",
    "IRIS_LABELS = IRIS.target\n",
    "\n",
    "TRAIN_FEATURES, TEST_FEATURES, TRAIN_LABELS, TEST_LABELS = train_test_split(IRIS_FEATURES, IRIS_LABELS, test_size=0.3, random_state=42)\n",
    "\n",
    "MODEL = RandomForestClassifier(n_estimators=3, random_state=42)\n",
    "MODEL.fit(TRAIN_FEATURES, TRAIN_LABELS)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Load Data from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Dropdown, VBox, Output, HTML, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Get available samples\n",
    "available_samples = list_available_samples()\n",
    "\n",
    "if not available_samples:\n",
    "    print(\"No samples found. Please run the previous cells to generate data first.\")\n",
    "else:\n",
    "    # Create dropdown options from available samples\n",
    "    dropdown_options = []\n",
    "    for sample_id, metadata in sorted(available_samples.items()):\n",
    "        original_sample = metadata['original_sample']\n",
    "        predicted_class = metadata['predicted_class']\n",
    "        target_class = metadata['target_class']\n",
    "        sample_index = metadata.get('sample_index', 'N/A')\n",
    "        timestamp = metadata.get('timestamp', 'N/A')\n",
    "        \n",
    "        # Format sample features\n",
    "        feature_str = \" | \".join([f\"{k}: {v:.2f}\" for k, v in original_sample.items()])\n",
    "        label = f\"Sample {sample_id} | idx:{sample_index} | {feature_str} | pred:{predicted_class} | target:{target_class}\"\n",
    "        dropdown_options.append((label, sample_id))\n",
    "    \n",
    "    print(f\"Found {len(dropdown_options)} available samples\")\n",
    "    print(\"Select a sample below to explore its counterfactual combinations and replications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive visualization explorer with hierarchical selection: Sample -> Combination -> Replication\n",
    "from ipywidgets import Dropdown, Output, VBox, HTML, Layout, IntSlider, HBox\n",
    "\n",
    "# Check if samples are available\n",
    "available_samples = list_available_samples()\n",
    "\n",
    "print(\"available_samples:\", available_samples.items())\n",
    "\n",
    "if not available_samples:\n",
    "    print(\"⚠ No samples found. Please run the experiment generation cells first.\")\n",
    "else:\n",
    "    # Build sample dropdown options\n",
    "    dropdown_options = []\n",
    "    for sample_id, metadata in sorted(available_samples.items()):\n",
    "        original_sample = metadata['original_sample']\n",
    "        predicted_class = metadata['predicted_class']\n",
    "        target_class = metadata['target_class']\n",
    "        sample_index = metadata.get('sample_index', 'N/A')\n",
    "        \n",
    "        feature_str = \" | \".join([f\"{k}: {v:.2f}\" for k, v in original_sample.items()])\n",
    "        label = f\"Sample {sample_id} | idx:{sample_index} | {feature_str} | pred:{predicted_class} | target:{target_class}\"\n",
    "        dropdown_options.append((label, sample_id))\n",
    "    \n",
    "    # Create sample selector dropdown\n",
    "    sample_dropdown = Dropdown(\n",
    "        options=dropdown_options,\n",
    "        value=dropdown_options[0][1] if dropdown_options else None,\n",
    "        description='Sample:',\n",
    "        layout=Layout(width='100%'),\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    # Define color mapping for rules\n",
    "    RULE_COLORS = {\n",
    "        'no_change': '#FF6B6B',  # Red\n",
    "        'non_increasing': '#4ECDC4',  # Teal\n",
    "        'non_decreasing': '#123456'  # blue\n",
    "    }\n",
    "\n",
    "    # Create combination slider\n",
    "    combination_slider = IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=0,\n",
    "        step=1,\n",
    "        description='Combination:',\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    # Create sample info display\n",
    "    sample_info = HTML(value=\"\", layout=Layout(margin='10px 0'))\n",
    "\n",
    "    # Create combined label to show features and current rules\n",
    "    combined_label = HTML(value=\"\")\n",
    "\n",
    "    # Create replication slider\n",
    "    replication_slider = IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=0,\n",
    "        step=1,\n",
    "        description='Replication:',\n",
    "        layout=Layout(width='500px')\n",
    "    )\n",
    "\n",
    "    # Create output areas\n",
    "    loading_status = HTML(value=\"\")  # Loading indicator\n",
    "    combination_output_area = Output()  # For PCA and Pairwise plots\n",
    "    replication_output_area = Output()  # For replication visualizations\n",
    "\n",
    "    # Slider labels for max values\n",
    "    combination_slider_label = HTML(value=\"/ 0\", layout=Layout(width='auto', margin='5px 0 0 10px'))\n",
    "    replication_slider_label = HTML(value=\"/ 0\", layout=Layout(width='auto', margin='5px 0 0 10px'))\n",
    "\n",
    "    # Global state for current sample - store as dict to avoid closure issues\n",
    "    STATE = {\n",
    "        'loader': None,\n",
    "        'metadata': None,\n",
    "        'available_samples': available_samples,  # Store in state for access in callbacks\n",
    "        'loader_cache': {},  # Cache loaders by sample_id to avoid reloading\n",
    "        'is_loading': False,  # Guard flag to prevent re-entrant calls\n",
    "    }\n",
    "\n",
    "    def create_combined_label(combination_idx, features_names, combination_labels):\n",
    "        \"\"\"Create a label combining features and their corresponding rules with color coding\"\"\"\n",
    "        if combination_idx >= len(combination_labels):\n",
    "            return \"<b>No visualizations available</b>\"\n",
    "        \n",
    "        rules_tuple = combination_labels[combination_idx]\n",
    "        label_parts = []\n",
    "        for feat, rule in zip(features_names, rules_tuple):\n",
    "            color = RULE_COLORS.get(rule, '#000000')\n",
    "            label_parts.append(f\"<b>{feat}=</b><span style='color: {color}; font-weight: bold;'>{rule}</span>\")\n",
    "        \n",
    "        return \"<br>\".join(label_parts)\n",
    "\n",
    "    def display_combination_plots(combination_idx):\n",
    "        \"\"\"Display PCA and Pairwise plots for selected combination - loads on demand\"\"\"\n",
    "        combination_output_area.clear_output(wait=True)\n",
    "        with combination_output_area:\n",
    "            loading_status.value = \"⏳ Loading combination data...\"\n",
    "            \n",
    "            # Lazy load the combination data\n",
    "            combination_viz = STATE['loader'].get_combination_data(combination_idx)\n",
    "            \n",
    "            loading_status.value = \"\"\n",
    "\n",
    "            if combination_viz.get('pca') is not None:\n",
    "                display_figure(combination_viz['pca'])\n",
    "\n",
    "            if combination_viz.get('pairwise') is not None:\n",
    "                display_figure(combination_viz['pairwise'])\n",
    "\n",
    "    def display_replication(combination_idx, replication_idx):\n",
    "        \"\"\"Display visualizations for selected replication - loads on demand\"\"\"\n",
    "        replication_output_area.clear_output(wait=True)\n",
    "        with replication_output_area:\n",
    "            loading_status.value = \"⏳ Loading replication data...\"\n",
    "            \n",
    "            # Lazy load the combination data (cached if already loaded)\n",
    "            combination_viz = STATE['loader'].get_combination_data(combination_idx)\n",
    "            \n",
    "            loading_status.value = \"\"\n",
    "            \n",
    "            if replication_idx >= len(combination_viz['replication']):\n",
    "                print(f\"⚠ Replication {replication_idx} not found\")\n",
    "                return\n",
    "                \n",
    "            replication_viz = combination_viz['replication'][replication_idx]\n",
    "            \n",
    "            print(f\"Replication {replication_idx + 1}:\")\n",
    "\n",
    "            # Display explanations\n",
    "            explanations = replication_viz.get('explanations', {})\n",
    "            for explanation_name, explanation_value in explanations.items():\n",
    "                print(f\"\\n{explanation_name}:\")\n",
    "                # Special formatting for Feature Modifications (list of dicts)\n",
    "                if explanation_name == 'Feature Modifications' and isinstance(explanation_value, list):\n",
    "                    for mod in explanation_value:\n",
    "                        feature_name = mod['feature_name']\n",
    "                        old_value = mod['old_value']\n",
    "                        new_value = mod['new_value']\n",
    "                        # Get constraints for this feature from target class\n",
    "                        target_class = STATE['metadata']['target_class']\n",
    "                        constraints = STATE['metadata']['constraints']\n",
    "                        target_class_constraints = constraints.get(f'Class {target_class}', [])\n",
    "                        # Convert feature name to match constraint format\n",
    "                        feature_key = feature_name.replace(' (cm)', '').replace(' ', '_')\n",
    "                        # Find the constraint for this feature\n",
    "                        feature_constraint = next((c for c in target_class_constraints if c['feature'] == feature_key), {})\n",
    "                        min_val = feature_constraint.get('min', None)\n",
    "                        max_val = feature_constraint.get('max', None)\n",
    "                        constraint_str = f\"(min: {min_val} -> max: {max_val})\" if min_val is not None or max_val is not None else \"\"\n",
    "                        print(f\"  Feature '{feature_name}': {old_value} → {new_value} {constraint_str}\")\n",
    "                else:\n",
    "                    print(explanation_value)\n",
    "\n",
    "            # Use nested visualizations list\n",
    "            for viz_idx, viz in enumerate(replication_viz.get('visualizations', [])):\n",
    "                display_figure(viz)\n",
    "\n",
    "    def load_sample(sample_id):\n",
    "        \"\"\"Load a sample and update all UI components\"\"\"\n",
    "        \n",
    "        # Guard against re-entrant calls\n",
    "        if STATE['is_loading']:\n",
    "            return\n",
    "        STATE['is_loading'] = True\n",
    "        \n",
    "        try:\n",
    "            # Check if we already have this sample cached\n",
    "            if sample_id in STATE['loader_cache']:\n",
    "                loading_status.value = f\"✓ Loading cached sample {sample_id}...\"\n",
    "                STATE['loader'] = STATE['loader_cache'][sample_id]\n",
    "                STATE['metadata'] = STATE['loader']._metadata\n",
    "            else:\n",
    "                loading_status.value = f\"⏳ Loading sample {sample_id}...\"\n",
    "                try:\n",
    "                    # Create lazy loader and load metadata\n",
    "                    STATE['loader'] = load_visualizations_data_lazy(sample_id)\n",
    "                    STATE['metadata'] = STATE['loader']._metadata\n",
    "                    # Cache the loader for future use\n",
    "                    STATE['loader_cache'][sample_id] = STATE['loader']\n",
    "                except Exception as e:\n",
    "                    loading_status.value = f\"✗ Error loading sample {sample_id}: {str(e)}\"\n",
    "                    print(f\"Error: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "                    return\n",
    "            \n",
    "            # Get sample metadata from available_samples for additional info\n",
    "            sample_metadata = STATE['available_samples'].get(sample_id, {})\n",
    "            \n",
    "            # Build sample info display\n",
    "            original_sample = STATE['metadata']['original_sample']\n",
    "            target_class = STATE['metadata']['target_class']\n",
    "            predicted_class = sample_metadata.get('predicted_class', 'N/A')\n",
    "            sample_index = sample_metadata.get('sample_index', 'N/A')\n",
    "            timestamp = sample_metadata.get('timestamp', 'N/A')\n",
    "            \n",
    "            # Format sample features\n",
    "            feature_lines = []\n",
    "            for feat_name, feat_value in original_sample.items():\n",
    "                feature_lines.append(f\"<b>{feat_name}:</b> {feat_value:.4f}\")\n",
    "            \n",
    "            sample_info.value = f\"\"\"\n",
    "            <div style=\"background-color: #f0f0f0; padding: 10px; border-radius: 5px; margin: 10px 0;\">\n",
    "                <b>Sample Information:</b><br>\n",
    "                <b>Sample ID:</b> {sample_id} | <b>Index:</b> {sample_index}<br>\n",
    "                <b>Generated:</b> {timestamp}<br>\n",
    "                <b>Predicted Class:</b> {predicted_class} → <b>Target Class:</b> {target_class}<br>\n",
    "                <br>\n",
    "                <b>Original Features:</b><br>\n",
    "                {' | '.join(feature_lines)}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "            # Update combination slider\n",
    "            num_combinations = STATE['metadata']['num_combinations']\n",
    "            combination_slider.max = max(0, num_combinations - 1)\n",
    "            combination_slider.value = 0\n",
    "            combination_slider_label.value = f\"/ {combination_slider.max}\"\n",
    "            \n",
    "            # Update combined label\n",
    "            if num_combinations > 0:\n",
    "                combined_label.value = create_combined_label(\n",
    "                    0, \n",
    "                    STATE['metadata']['features_names'],\n",
    "                    STATE['metadata']['combination_labels']\n",
    "                )\n",
    "                \n",
    "                # Load first combination to get replication count\n",
    "                combination_viz = STATE['loader'].get_combination_data(0)\n",
    "                num_replications = len(combination_viz['replication'])\n",
    "                \n",
    "                # Update replication slider\n",
    "                replication_slider.max = max(0, num_replications - 1)\n",
    "                replication_slider.value = 0\n",
    "                replication_slider_label.value = f\"/ {replication_slider.max}\"\n",
    "                \n",
    "                loading_status.value = f\"✓ Sample {sample_id} loaded ({num_combinations} combinations, {sum(STATE['metadata']['combination_replication_counts'])} total replications)\"\n",
    "                \n",
    "                # Display first combination and replication\n",
    "                display_combination_plots(0)\n",
    "                display_replication(0, 0)\n",
    "            else:\n",
    "                combined_label.value = \"<b>No combinations available</b>\"\n",
    "                loading_status.value = f\"✓ Sample {sample_id} loaded (no combinations)\"\n",
    "                \n",
    "            # --- FIX: Set global variables for summary table cell ---\n",
    "            global CURRENT_LAZY_LOADER, CURRENT_METADATA\n",
    "            CURRENT_LAZY_LOADER = STATE['loader']\n",
    "            CURRENT_METADATA = STATE['metadata']\n",
    "            # ------------------------------------------------------\n",
    "        except Exception as e:\n",
    "            loading_status.value = f\"✗ Error displaying sample {sample_id}: {str(e)}\"\n",
    "            print(f\"Error: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            STATE['is_loading'] = False\n",
    "\n",
    "    def on_sample_change(change):\n",
    "        \"\"\"Handle sample selection change\"\"\"\n",
    "        sample_id = change['new']\n",
    "        combination_output_area.clear_output()\n",
    "        replication_output_area.clear_output()\n",
    "        load_sample(sample_id)\n",
    "\n",
    "    def on_combination_change(change):\n",
    "        \"\"\"Handle combination selection change\"\"\"\n",
    "        # Skip if we're in the middle of loading a sample\n",
    "        if STATE['is_loading']:\n",
    "            return\n",
    "            \n",
    "        combination_idx = change['new']\n",
    "        \n",
    "        # Update combined label with features and rules\n",
    "        combined_label.value = create_combined_label(\n",
    "            combination_idx,\n",
    "            STATE['metadata']['features_names'],\n",
    "            STATE['metadata']['combination_labels']\n",
    "        )\n",
    "        \n",
    "        # Get combination data to determine replication count\n",
    "        combination_viz = STATE['loader'].get_combination_data(combination_idx)\n",
    "        \n",
    "        # Update replication slider range\n",
    "        num_replications = len(combination_viz['replication'])\n",
    "        replication_slider.max = max(0, num_replications - 1)\n",
    "        replication_slider.value = 0\n",
    "        replication_slider_label.value = f\"/ {replication_slider.max}\"\n",
    "        \n",
    "        # Display combination plots\n",
    "        display_combination_plots(combination_idx)\n",
    "        \n",
    "        # Display first replication\n",
    "        if num_replications > 0:\n",
    "            display_replication(combination_idx, 0)\n",
    "\n",
    "    def on_replication_change(change):\n",
    "        \"\"\"Handle replication selection change\"\"\"\n",
    "        # Skip if we're in the middle of loading a sample\n",
    "        if STATE['is_loading']:\n",
    "            return\n",
    "            \n",
    "        combination_idx = combination_slider.value\n",
    "        replication_idx = change['new']\n",
    "        display_replication(combination_idx, replication_idx)\n",
    "\n",
    "    # Register observers (fresh widgets don't need unobserve)\n",
    "    sample_dropdown.observe(on_sample_change, names='value')\n",
    "    combination_slider.observe(on_combination_change, names='value')\n",
    "    replication_slider.observe(on_replication_change, names='value')\n",
    "\n",
    "    # Wrap sliders with labels\n",
    "    combination_slider_with_label = HBox([combination_slider, combination_slider_label])\n",
    "    replication_slider_with_label = HBox([replication_slider, replication_slider_label])\n",
    "\n",
    "    # Display all controls in a single VBox\n",
    "    display(VBox([\n",
    "        sample_dropdown,\n",
    "        loading_status,\n",
    "        sample_info,\n",
    "        combined_label,\n",
    "        combination_slider_with_label,\n",
    "        combination_output_area,\n",
    "        replication_slider_with_label,\n",
    "        replication_output_area\n",
    "    ]))\n",
    "\n",
    "    # Auto-load first sample\n",
    "    if dropdown_options:\n",
    "        load_sample(dropdown_options[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Summary Table of All Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import IntSlider, VBox, HBox, Output, Button, Layout, HTML as HTMLWidget\n",
    "\n",
    "# Use current loaded data if available\n",
    "if 'CURRENT_LAZY_LOADER' in globals() and CURRENT_LAZY_LOADER is not None:\n",
    "    print(f\"Building summary table for currently loaded sample...\")\n",
    "    print(\"⏳ This may take a moment as all data needs to be loaded...\")\n",
    "    \n",
    "    FEATURES_NAMES = CURRENT_METADATA['features_names']\n",
    "    \n",
    "    # Build a comprehensive table from the visualizations data structure\n",
    "    table_data = []\n",
    "\n",
    "    for combination_idx in range(CURRENT_METADATA['num_combinations']):\n",
    "        # Lazy load this combination\n",
    "        combination_viz = CURRENT_LAZY_LOADER.get_combination_data(combination_idx)\n",
    "        \n",
    "        # Get the rules for this combination\n",
    "        rules_tuple = combination_viz['label']\n",
    "        rules_dict = dict(zip(FEATURES_NAMES, rules_tuple))\n",
    "        \n",
    "        # Iterate through each replication\n",
    "        for replication_idx, replication_viz in enumerate(combination_viz['replication']):\n",
    "            row = {\n",
    "                'Combination': combination_idx + 1,\n",
    "                'Replication': replication_idx + 1,\n",
    "            }\n",
    "            \n",
    "            # Add rule columns\n",
    "            for feature_name in FEATURES_NAMES:\n",
    "                row[f'Rule_{feature_name}'] = rules_dict[feature_name]\n",
    "            \n",
    "            # Add counterfactual feature values\n",
    "            counterfactual = replication_viz['counterfactual']\n",
    "            for feature_name in FEATURES_NAMES:\n",
    "                row[f'CF_{feature_name}'] = counterfactual.get(feature_name, None)\n",
    "            \n",
    "            # Add counts of visualizations and explanations\n",
    "            row['Num_Visualizations'] = len(replication_viz.get('visualizations', []))\n",
    "            row['Num_Explanations'] = len(replication_viz.get('explanations', {}))\n",
    "            \n",
    "            # Add explanation content from dictionary\n",
    "            explanations = replication_viz.get('explanations', {})\n",
    "            for explanation_name, explanation_value in explanations.items():\n",
    "                # Special handling for Feature Modifications (list of dicts)\n",
    "                if explanation_name == 'Feature Modifications' and isinstance(explanation_value, list):\n",
    "                    # Format as readable HTML text: \"feature, old => new (delta)\"\n",
    "                    formatted_mods = []\n",
    "                    for mod in explanation_value:\n",
    "                        feature_name = str(mod['feature_name'])\n",
    "                        old_val = float(mod['old_value'])\n",
    "                        new_val = float(mod['new_value'])\n",
    "                        delta = new_val - old_val\n",
    "                        formatted_mods.append(f\"{feature_name}, {old_val} => {new_val} ({delta:+.2f})\")\n",
    "                    # Join with HTML <br> so it renders one per line in DataFrame HTML representation\n",
    "                    row[explanation_name] = \"<br>\".join(formatted_mods)\n",
    "                else:\n",
    "                    row[explanation_name] = explanation_value\n",
    "            \n",
    "            # Extract any other keys that might exist in replication_viz\n",
    "            for key in replication_viz.keys():\n",
    "                if key not in ['counterfactual', 'cf_model', 'visualizations', 'explanations']:\n",
    "                    row[key] = replication_viz[key]\n",
    "            \n",
    "            table_data.append(row)\n",
    "\n",
    "    # Create DataFrame\n",
    "    summary_df = pd.DataFrame(table_data)\n",
    "\n",
    "    # Display summary statistics\n",
    "    print(f\"Total Combinations: {CURRENT_METADATA['num_combinations']}\")\n",
    "    print(f\"Total Replications: {len(summary_df)}\")\n",
    "    if CURRENT_METADATA['num_combinations'] > 0:\n",
    "        print(f\"Average Replications per Combination: {len(summary_df) / CURRENT_METADATA['num_combinations']:.2f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Display the summary table (rendering HTML so <br> shows as new lines)\n",
    "    print(\"\\n\" + \"=\" * 150)\n",
    "    print(\"DETAILED COUNTERFACTUAL SUMMARY TABLE\")\n",
    "    print(\"=\" * 150)\n",
    "    display(HTML(summary_df.to_html(escape=False)))\n",
    "else:\n",
    "    print(\"⚠ No sample loaded. Please run the interactive visualization cell above and select a sample first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Scamander')\n",
    "\n",
    "from cf_eval.metrics import (\n",
    "    nbr_valid_cf,\n",
    "    perc_valid_cf,\n",
    "    continuous_distance,\n",
    "    avg_nbr_changes_per_cf,\n",
    "    nbr_changes_per_cf\n",
    ")\n",
    "\n",
    "# Check if we have loaded data\n",
    "if 'CURRENT_LAZY_LOADER' in globals() and CURRENT_LAZY_LOADER is not None:\n",
    "    print(\"=\"*80)\n",
    "    print(\"COUNTERFACTUAL QUALITY METRICS EVALUATION\")\n",
    "    print(\"=\"*80)\n",
    "    print()\n",
    "    \n",
    "    # Get original sample and metadata\n",
    "    original_sample = CURRENT_METADATA['original_sample']\n",
    "    target_class = CURRENT_METADATA['target_class']\n",
    "    \n",
    "    # Convert original sample dict to numpy array\n",
    "    x_original = np.array([original_sample[feat] for feat in CURRENT_METADATA['features_names']])\n",
    "    y_original = MODEL.predict(x_original.reshape(1, -1))[0]\n",
    "    \n",
    "    print(f\"Original Sample: {original_sample}\")\n",
    "    print(f\"Predicted Class: {y_original} → Target Class: {target_class}\")\n",
    "    print()\n",
    "    \n",
    "    # Collect all counterfactuals from all combinations\n",
    "    all_metrics = []\n",
    "    \n",
    "    for combination_idx in range(CURRENT_METADATA['num_combinations']):\n",
    "        combination_viz = CURRENT_LAZY_LOADER.get_combination_data(combination_idx)\n",
    "        rules_tuple = combination_viz['label']\n",
    "        \n",
    "        # Collect counterfactuals for this combination\n",
    "        cf_list = []\n",
    "        for replication_idx, replication_viz in enumerate(combination_viz['replication']):\n",
    "            cf_dict = replication_viz['counterfactual']\n",
    "            cf_array = np.array([cf_dict[feat] for feat in CURRENT_METADATA['features_names']])\n",
    "            cf_list.append(cf_array)\n",
    "        \n",
    "        if len(cf_list) == 0:\n",
    "            continue\n",
    "        \n",
    "        cf_array = np.array(cf_list)\n",
    "        \n",
    "        # ====================\n",
    "        # METRIC 1: Validity\n",
    "        # ====================\n",
    "        # Number and percentage of counterfactuals that achieve the desired class\n",
    "        num_valid = nbr_valid_cf(cf_array, MODEL, y_original, y_desidered=target_class)\n",
    "        pct_valid = perc_valid_cf(cf_array, MODEL, y_original, y_desidered=target_class)\n",
    "        \n",
    "        # ====================\n",
    "        # METRIC 2: Proximity (Distance)\n",
    "        # ====================\n",
    "        # How close are the counterfactuals to the original sample (lower is better)\n",
    "        # Using Euclidean distance on continuous features (all Iris features are continuous)\n",
    "        continuous_features = list(range(len(CURRENT_METADATA['features_names'])))\n",
    "        avg_distance = continuous_distance(x_original, cf_array, continuous_features, metric='euclidean')\n",
    "        min_distance = continuous_distance(x_original, cf_array, continuous_features, metric='euclidean', agg='min')\n",
    "        max_distance = continuous_distance(x_original, cf_array, continuous_features, metric='euclidean', agg='max')\n",
    "        \n",
    "        # ====================\n",
    "        # METRIC 3: Sparsity (Number of Changes)\n",
    "        # ====================\n",
    "        # How many features were changed (fewer is better - more actionable)\n",
    "        avg_changes = avg_nbr_changes_per_cf(x_original, cf_array, continuous_features)\n",
    "        changes_per_cf = nbr_changes_per_cf(x_original, cf_array, continuous_features)\n",
    "        \n",
    "        all_metrics.append({\n",
    "            'Combination': combination_idx + 1,\n",
    "            'Rules': str(rules_tuple),\n",
    "            'Num_CFs': len(cf_list),\n",
    "            'Valid_CFs': num_valid,\n",
    "            'Validity_%': f\"{pct_valid*100:.1f}%\",\n",
    "            'Avg_Distance': f\"{avg_distance:.4f}\",\n",
    "            'Min_Distance': f\"{min_distance:.4f}\",\n",
    "            'Max_Distance': f\"{max_distance:.4f}\",\n",
    "            'Avg_Changes': f\"{avg_changes:.2f}\",\n",
    "            'Changes_Detail': [f\"{c:.1f}\" for c in changes_per_cf]\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and display\n",
    "    metrics_df = pd.DataFrame(all_metrics)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METRICS BY COMBINATION\")\n",
    "    print(\"=\"*80)\n",
    "    display(HTML(metrics_df.to_html(escape=False, index=False)))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"METRIC EXPLANATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\"\"\n",
    "    1. Validity: Percentage of counterfactuals that successfully achieve the target class\n",
    "       - Higher is better (100% means all CFs are valid)\n",
    "    \n",
    "    2. Proximity (Distance): Average Euclidean distance from original sample\n",
    "       - Lower is better (smaller changes from original)\n",
    "    \n",
    "    3. Sparsity (Avg Changes): Average number of features modified per counterfactual\n",
    "       - Lower is better (fewer features changed = more actionable)\n",
    "    \"\"\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠ No sample loaded. Please run the interactive visualization cells above first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
