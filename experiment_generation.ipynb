{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# CounterFactual Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import Bunch\n",
    "from typing import cast\n",
    "from CounterFactualModel import CounterFactualModel\n",
    "from ConstraintParser import ConstraintParser\n",
    "import CounterFactualVisualizer as CounterFactualVisualizer\n",
    "importlib.reload(CounterFactualVisualizer)\n",
    "from CounterFactualVisualizer import (plot_pca_with_counterfactual, plot_sample_and_counterfactual_heatmap, \n",
    "                                     plot_pca_loadings, plot_constraints, \n",
    "                                     plot_sample_and_counterfactual_comparison, plot_pairwise_with_counterfactual_df,\n",
    "                                     plot_pca_with_counterfactuals, plot_explainer_summary)\n",
    "from CounterFactualExplainer import CounterFactualExplainer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File-based storage utilities\n",
    "import pickle\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directory for storing experiment results\n",
    "OUTPUT_DIR = \"experiment_results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def get_sample_id(original_sample):\n",
    "    \"\"\"Generate a unique ID for a sample based on its feature values\"\"\"\n",
    "    # Create a hash from feature values\n",
    "    feature_str = \"_\".join([f\"{k}_{v:.4f}\" for k, v in sorted(original_sample.items())])\n",
    "    return hash(feature_str) & 0x7FFFFFFF  # Positive integer hash\n",
    "\n",
    "def save_sample_metadata(sample_id, original_sample, predicted_class, target_class, sample_index=None):\n",
    "    \"\"\"Save metadata about the sample\"\"\"\n",
    "    metadata = {\n",
    "        'sample_id': sample_id,\n",
    "        'original_sample': original_sample,\n",
    "        'predicted_class': predicted_class,\n",
    "        'target_class': target_class,\n",
    "        'sample_index': sample_index,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    filepath = os.path.join(OUTPUT_DIR, f\"sample_{sample_id}_metadata.pkl\")\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    print(f\"Saved sample metadata to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_visualizations_data(sample_id, visualizations, original_sample, constraints, features_names, target_class):\n",
    "    \"\"\"Save the visualizations data structure to disk\"\"\"\n",
    "    data = {\n",
    "        'sample_id': sample_id,\n",
    "        'original_sample': original_sample,\n",
    "        'visualizations': visualizations,\n",
    "        'constraints': constraints,\n",
    "        'features_names': features_names,\n",
    "        'target_class': target_class,\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    filepath = os.path.join(OUTPUT_DIR, f\"sample_{sample_id}_visualizations.pkl\")\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Saved visualizations data to {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def load_visualizations_data(sample_id):\n",
    "    \"\"\"Load the visualizations data structure from disk\"\"\"\n",
    "    filepath = os.path.join(OUTPUT_DIR, f\"sample_{sample_id}_visualizations.pkl\")\n",
    "    if not os.path.exists(filepath):\n",
    "        raise FileNotFoundError(f\"No visualizations data found for sample {sample_id}\")\n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Loaded visualizations data from {filepath}\")\n",
    "    return data\n",
    "\n",
    "def list_available_samples():\n",
    "    \"\"\"List all available sample IDs that have been processed\"\"\"\n",
    "    samples = {}\n",
    "    for filename in os.listdir(OUTPUT_DIR):\n",
    "        if filename.startswith(\"sample_\") and filename.endswith(\"_metadata.pkl\"):\n",
    "            sample_id = int(filename.split(\"_\")[1])\n",
    "            filepath = os.path.join(OUTPUT_DIR, filename)\n",
    "            with open(filepath, 'rb') as f:\n",
    "                metadata = pickle.load(f)\n",
    "            samples[sample_id] = metadata\n",
    "    return samples\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Available samples: {len(list_available_samples())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Setup + Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_COLORS_LIST = ['purple', 'green', 'orange']\n",
    "IRIS: Bunch = cast(Bunch, load_iris())\n",
    "IRIS_FEATURES = IRIS.data\n",
    "IRIS_LABELS = IRIS.target\n",
    "\n",
    "TRAIN_FEATURES, TEST_FEATURES, TRAIN_LABELS, TEST_LABELS = train_test_split(IRIS_FEATURES, IRIS_LABELS, test_size=0.3, random_state=42)\n",
    "\n",
    "MODEL = RandomForestClassifier(n_estimators=3, random_state=42)\n",
    "MODEL.fit(TRAIN_FEATURES, TRAIN_LABELS)\n",
    "\n",
    "CONSTRAINT_PARSER = ConstraintParser(\"constraints/custom_l100_pv0.001_t2_dpg_metrics.txt\")\n",
    "CONSTRAINTS = CONSTRAINT_PARSER.read_constraints_from_file()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 30 random samples from the Iris dataset\n",
    "from ipywidgets import RadioButtons, VBox, Output, Button, Layout\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "num_samples = 30\n",
    "total_samples = len(IRIS_FEATURES)\n",
    "\n",
    "# Generate random indices\n",
    "random_indices = np.random.choice(total_samples, size=min(num_samples, total_samples), replace=False)\n",
    "\n",
    "# Create DataFrame with random samples\n",
    "random_samples_df = pd.DataFrame(\n",
    "    IRIS_FEATURES[random_indices],\n",
    "    columns=IRIS.feature_names\n",
    ")\n",
    "random_samples_df['target'] = IRIS_LABELS[random_indices]\n",
    "random_samples_df['target_name'] = [IRIS.target_names[label] for label in IRIS_LABELS[random_indices]]\n",
    "random_samples_df['index'] = random_indices\n",
    "\n",
    "print(f\"Displaying {len(random_samples_df)} random samples from the Iris dataset:\")\n",
    "print(f\"Total dataset size: {total_samples}\\n\")\n",
    "\n",
    "# Create a temporary CounterFactualModel instance to validate constraints\n",
    "temp_cf_model = CounterFactualModel(MODEL, CONSTRAINTS, verbose=False)\n",
    "\n",
    "# Create radio button options with constraint validation\n",
    "radio_options = []\n",
    "for idx, row in random_samples_df.iterrows():\n",
    "    # Convert row to sample dict\n",
    "    sample_dict = {\n",
    "        'sepal length (cm)': row['sepal length (cm)'],\n",
    "        'sepal width (cm)': row['sepal width (cm)'],\n",
    "        'petal length (cm)': row['petal length (cm)'],\n",
    "        'petal width (cm)': row['petal width (cm)']\n",
    "    }\n",
    "    \n",
    "    # Get the target class for this sample\n",
    "    sample_target_class = int(row['target'])\n",
    "    \n",
    "    # Validate constraints for this sample against its own class constraints\n",
    "    is_valid, penalty = temp_cf_model.validate_constraints(sample_dict, sample_dict, sample_target_class)\n",
    "    \n",
    "    # Create validation indicator\n",
    "    validation_status = \"✓\" if is_valid else f\"✗ (penalty: {penalty:.2f})\"\n",
    "    \n",
    "    # Build label with constraint validation\n",
    "    feature_str = \" | \".join([f\"{col}: {row[col]:.2f}\" for col in IRIS.feature_names])\n",
    "    label = f\"#{idx} | idx:{int(row['index'])} | {validation_status} | {feature_str} | class: {int(row['target'])} ({row['target_name']})\"\n",
    "    radio_options.append((label, idx))\n",
    "\n",
    "# Create radio buttons widget\n",
    "sample_selector = RadioButtons(\n",
    "    options=radio_options,\n",
    "    value=random_samples_df.index[0],  # Select first sample by default\n",
    "    description='Select:',\n",
    "    layout=Layout(width='100%', height='400px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Output area for displaying selected sample details\n",
    "output_area = Output()\n",
    "\n",
    "# Output area for constraint visualizations\n",
    "constraints_viz_area = Output()\n",
    "\n",
    "# Button to confirm selection\n",
    "confirm_button = Button(\n",
    "    description='Use Selected Sample',\n",
    "    button_style='success',\n",
    "    tooltip='Click to update ORIGINAL_SAMPLE with the selected sample',\n",
    "    layout=Layout(width='200px')\n",
    ")\n",
    "\n",
    "# Variable to track if selection was made\n",
    "selection_confirmed = False\n",
    "\n",
    "def update_sample_and_plots(selected_idx):\n",
    "    \"\"\"Update ORIGINAL_SAMPLE and re-render constraint plots\"\"\"\n",
    "    global ORIGINAL_SAMPLE, SAMPLE_DATAFRAME\n",
    "    selected_row = random_samples_df.loc[selected_idx]\n",
    "    \n",
    "    # Update ORIGINAL_SAMPLE\n",
    "    ORIGINAL_SAMPLE = {\n",
    "        'sepal length (cm)': selected_row['sepal length (cm)'],\n",
    "        'sepal width (cm)': selected_row['sepal width (cm)'],\n",
    "        'petal length (cm)': selected_row['petal length (cm)'],\n",
    "        'petal width (cm)': selected_row['petal width (cm)']\n",
    "    }\n",
    "    SAMPLE_DATAFRAME = pd.DataFrame([ORIGINAL_SAMPLE])\n",
    "    \n",
    "    # Get the sample class\n",
    "    sample_class = int(selected_row['target'])\n",
    "    \n",
    "    # Update output area with sample info\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(f\"Selected sample (original index: {int(selected_row['index'])}):\")\n",
    "        print(f\"Target class: {sample_class} ({selected_row['target_name']})\")\n",
    "        \n",
    "        # Validate and show constraint status\n",
    "        is_valid, penalty = temp_cf_model.validate_constraints(ORIGINAL_SAMPLE, ORIGINAL_SAMPLE, sample_class)\n",
    "        print(f\"Constraint validation: {'✓ Valid' if is_valid else f'✗ Invalid (penalty: {penalty:.2f})'}\")\n",
    "        \n",
    "        print(\"\\nCurrent ORIGINAL_SAMPLE values:\")\n",
    "        for key, value in ORIGINAL_SAMPLE.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Update constraint visualizations with sample_class\n",
    "    with constraints_viz_area:\n",
    "        clear_output(wait=True)\n",
    "        display(plot_constraints(CONSTRAINTS, overlapping=False, class_colors_list=CLASS_COLORS_LIST, sample=ORIGINAL_SAMPLE, sample_class=sample_class))\n",
    "        display(plot_constraints(CONSTRAINTS, overlapping=True, class_colors_list=CLASS_COLORS_LIST, sample=ORIGINAL_SAMPLE, sample_class=sample_class))\n",
    "\n",
    "def on_sample_change(change):\n",
    "    \"\"\"Handle radio button selection change\"\"\"\n",
    "    selected_idx = change['new']\n",
    "    update_sample_and_plots(selected_idx)\n",
    "\n",
    "def on_confirm_click(b):\n",
    "    global selection_confirmed\n",
    "    selection_confirmed = True\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        print(\"✓ ORIGINAL_SAMPLE confirmed!\")\n",
    "        selected_idx = sample_selector.value\n",
    "        selected_row = random_samples_df.loc[selected_idx]\n",
    "        print(f\"\\nConfirmed sample (original index: {int(selected_row['index'])}):\")\n",
    "        print(f\"Target class: {int(selected_row['target'])} ({selected_row['target_name']})\")\n",
    "        \n",
    "        # Validate and show constraint status\n",
    "        sample_target_class = int(selected_row['target'])\n",
    "        is_valid, penalty = temp_cf_model.validate_constraints(ORIGINAL_SAMPLE, ORIGINAL_SAMPLE, sample_target_class)\n",
    "        print(f\"Constraint validation: {'✓ Valid' if is_valid else f'✗ Invalid (penalty: {penalty:.2f})'}\")\n",
    "        \n",
    "        print(\"\\nConfirmed ORIGINAL_SAMPLE values:\")\n",
    "        for key, value in ORIGINAL_SAMPLE.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "# Attach event handlers\n",
    "sample_selector.observe(on_sample_change, names='value')\n",
    "confirm_button.on_click(on_confirm_click)\n",
    "\n",
    "# Display the widgets\n",
    "display(VBox([sample_selector, confirm_button, output_area, constraints_viz_area]))\n",
    "\n",
    "# Auto-select first sample for \"Run All\" functionality\n",
    "if not selection_confirmed:\n",
    "    selected_idx = random_samples_df.index[0]\n",
    "    update_sample_and_plots(selected_idx)\n",
    "    print(f\"\\n→ First sample auto-selected (index: {int(random_samples_df.loc[selected_idx]['index'])}, class: {random_samples_df.loc[selected_idx]['target_name']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables depend on ORIGINAL_SAMPLE and must be set after sample selection\n",
    "SAMPLE_DATAFRAME = pd.DataFrame([ORIGINAL_SAMPLE])\n",
    "ORIGINAL_SAMPLE_PREDICTED_CLASS = MODEL.predict(SAMPLE_DATAFRAME)\n",
    "\n",
    "COUNTERFACTUAL_DPG = CounterFactualModel(MODEL, CONSTRAINTS, verbose=True)\n",
    "\n",
    "FEATURES_NAMES = list(ORIGINAL_SAMPLE.keys())\n",
    "RULES = ['no_change', 'non_increasing', 'non_decreasing']\n",
    "RULES_COMBINATIONS = list(itertools.product(RULES, repeat=len(FEATURES_NAMES)))\n",
    "\n",
    "TARGET_CLASS = 0\n",
    "\n",
    "\n",
    "NUMBER_OF_COMBINATIONS_TO_TEST = len(RULES_COMBINATIONS) # 81\n",
    "# NUMBER_OF_COMBINATIONS_TO_TEST = 9\n",
    "NUMBER_OF_REPLICATIONS_PER_COMBINATION = 5\n",
    "INITIAL_POPULATION_SIZE = 20\n",
    "MAX_GENERATIONS = 60\n",
    "\n",
    "# Generate and save sample ID and metadata\n",
    "SAMPLE_ID = get_sample_id(ORIGINAL_SAMPLE)\n",
    "selected_row = random_samples_df.loc[sample_selector.value]\n",
    "SAMPLE_INDEX = int(selected_row['index'])\n",
    "save_sample_metadata(SAMPLE_ID, ORIGINAL_SAMPLE, ORIGINAL_SAMPLE_PREDICTED_CLASS[0], TARGET_CLASS, SAMPLE_INDEX)\n",
    "\n",
    "print(f\"Sample ID: {SAMPLE_ID}\")\n",
    "print(f\"Original Predicted Class: {ORIGINAL_SAMPLE_PREDICTED_CLASS[0]}\")\n",
    "print(f\"Total possible rule combinations: {len(RULES_COMBINATIONS)}\")\n",
    "print(f\"Testing {NUMBER_OF_COMBINATIONS_TO_TEST} combinations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Constraints Extracted from DPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_pca_loadings(IRIS_FEATURES, IRIS.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Generate Counterfactuals with All Rule Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress, HTML, HBox, Output, Layout\n",
    "from IPython.display import display, clear_output\n",
    "import sys\n",
    "\n",
    "# Create progress widget with fixed positioning\n",
    "progress_widget = IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=NUMBER_OF_COMBINATIONS_TO_TEST,\n",
    "    description='',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal',\n",
    "    layout=Layout(width='500px')\n",
    ")\n",
    "\n",
    "progress_text = HTML(value='<b>Progress: 0 / ' + str(NUMBER_OF_COMBINATIONS_TO_TEST) + '</b>')\n",
    "progress_container = HBox([progress_widget, progress_text], layout=Layout(width='100%', padding='10px'))\n",
    "\n",
    "# Display the fixed progress widget and scrolling output area\n",
    "display(progress_container)\n",
    "\n",
    "counterfactuals_df_combinations = []\n",
    "visualizations = []\n",
    "\n",
    "for combination_num, combination in enumerate(RULES_COMBINATIONS[:NUMBER_OF_COMBINATIONS_TO_TEST]):\n",
    "    # Update progress widget\n",
    "    progress_widget.value = combination_num + 1\n",
    "    progress_text.value = f'<b>Progress: {combination_num + 1} / {NUMBER_OF_COMBINATIONS_TO_TEST}</b>'\n",
    "    \n",
    "    dict_non_actionable = dict(zip(FEATURES_NAMES, combination))\n",
    "    counterfactuals_df_replications = []\n",
    "    combination_viz = {\n",
    "        'label': combination,\n",
    "        'pairwise': None,\n",
    "        'pca': None,\n",
    "        'replication': []\n",
    "    }\n",
    "    \n",
    "    # Track if we should skip this combination\n",
    "    skip_combination = False\n",
    "    \n",
    "    for replication in range(NUMBER_OF_REPLICATIONS_PER_COMBINATION):\n",
    "        # If 3rd replication failed, skip the rest of this combination\n",
    "        if skip_combination:\n",
    "            break\n",
    "            \n",
    "        COUNTERFACTUAL_DPG = CounterFactualModel(MODEL, CONSTRAINTS)\n",
    "        COUNTERFACTUAL_DPG.dict_non_actionable = dict_non_actionable\n",
    "\n",
    "        counterfactual = COUNTERFACTUAL_DPG.generate_counterfactual(ORIGINAL_SAMPLE, TARGET_CLASS, INITIAL_POPULATION_SIZE, MAX_GENERATIONS)\n",
    "        if (counterfactual == None):\n",
    "            # If 3rd replication (index 2) fails, skip the rest of the combination\n",
    "            if replication == 2:\n",
    "                skip_combination = True\n",
    "            continue\n",
    "    \n",
    "        # Store counterfactual and model in replication_viz object\n",
    "        replication_viz = {\n",
    "            'counterfactual': counterfactual,\n",
    "            'cf_model': COUNTERFACTUAL_DPG,  # Store the model so we can access fitness data later\n",
    "            'visualizations': [],\n",
    "            'explanations': {}  # Changed to dictionary\n",
    "        }\n",
    "        combination_viz['replication'].append(replication_viz)\n",
    "\n",
    "        # Prepare data for DataFrame\n",
    "        cf_data = counterfactual.copy()\n",
    "        cf_data.update({'Rule_' + k: v for k, v in dict_non_actionable.items()})\n",
    "        cf_data['Replication'] = replication + 1\n",
    "        counterfactuals_df_replications.append(cf_data)\n",
    "    \n",
    "    # Convert replications to DataFrame (no plotting yet)\n",
    "    if counterfactuals_df_replications:\n",
    "        counterfactuals_df_replications = pd.DataFrame(counterfactuals_df_replications)\n",
    "        \n",
    "        # Add all replications to the overall combinations list\n",
    "        counterfactuals_df_combinations.extend(counterfactuals_df_replications.to_dict('records'))\n",
    "    \n",
    "    if(combination_viz['replication']):\n",
    "        visualizations.append(combination_viz)\n",
    "\n",
    "\n",
    "# Convert all combinations to DataFrame\n",
    "counterfactuals_df_combinations = pd.DataFrame(counterfactuals_df_combinations)\n",
    "\n",
    "# Save the raw counterfactuals data (without visualizations, just the data)\n",
    "raw_data = {\n",
    "    'sample_id': SAMPLE_ID,\n",
    "    'original_sample': ORIGINAL_SAMPLE,\n",
    "    'target_class': TARGET_CLASS,\n",
    "    'features_names': FEATURES_NAMES,\n",
    "    'visualizations_structure': []\n",
    "}\n",
    "\n",
    "# Save a lightweight version without cf_model objects (which can't be pickled easily)\n",
    "for combination_viz in visualizations:\n",
    "    combo_copy = {\n",
    "        'label': combination_viz['label'],\n",
    "        'replication': []\n",
    "    }\n",
    "    for replication_viz in combination_viz['replication']:\n",
    "        # Extract fitness history from the model before discarding it\n",
    "        fitness_history = replication_viz['cf_model'].fitness_history if hasattr(replication_viz['cf_model'], 'fitness_history') else []\n",
    "        \n",
    "        rep_copy = {\n",
    "            'counterfactual': replication_viz['counterfactual'],\n",
    "            'fitness_history': fitness_history\n",
    "        }\n",
    "        combo_copy['replication'].append(rep_copy)\n",
    "    raw_data['visualizations_structure'].append(combo_copy)\n",
    "\n",
    "raw_filepath = os.path.join(OUTPUT_DIR, f\"sample_{SAMPLE_ID}_raw_counterfactuals.pkl\")\n",
    "with open(raw_filepath, 'wb') as f:\n",
    "    pickle.dump(raw_data, f)\n",
    "print(f\"\\nSaved raw counterfactuals data to {raw_filepath}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Generate Visualizations for Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create progress widget for visualization generation\n",
    "viz_progress_widget = IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(visualizations),\n",
    "    description='Visualizations:',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal',\n",
    "    layout=Layout(width='500px')\n",
    ")\n",
    "\n",
    "viz_progress_text = HTML(value='<b>Progress: 0 / ' + str(len(visualizations)) + '</b>')\n",
    "viz_progress_container = HBox([viz_progress_widget, viz_progress_text], layout=Layout(width='100%', padding='10px'))\n",
    "\n",
    "# Display the fixed progress widget and scrolling output area\n",
    "display(viz_progress_container)\n",
    "\n",
    "# Iterate over all combinations and generate visualizations\n",
    "for combination_idx, combination_viz in enumerate(visualizations):\n",
    "    # Update progress widget\n",
    "    viz_progress_widget.value = combination_idx + 1\n",
    "    viz_progress_text.value = f'<b>Progress: {combination_idx + 1} / {len(visualizations)}</b>'\n",
    "    \n",
    "    dict_non_actionable = dict(zip(FEATURES_NAMES, combination_viz['label']))\n",
    "    \n",
    "    # Generate visualizations for each replication\n",
    "    for replication_idx, replication_viz in enumerate(combination_viz['replication']):\n",
    "        counterfactual = replication_viz['counterfactual']\n",
    "        COUNTERFACTUAL_DPG = replication_viz['cf_model']  # Use the stored model instead of regenerating\n",
    "      \n",
    "        # Generate replication visualizations\n",
    "        replication_visualizations = [\n",
    "            plot_sample_and_counterfactual_heatmap(ORIGINAL_SAMPLE, ORIGINAL_SAMPLE_PREDICTED_CLASS, counterfactual, MODEL.predict(pd.DataFrame([counterfactual])), dict_non_actionable),\n",
    "            plot_sample_and_counterfactual_comparison(MODEL, ORIGINAL_SAMPLE, SAMPLE_DATAFRAME, counterfactual,CONSTRAINTS, CLASS_COLORS_LIST),\n",
    "            COUNTERFACTUAL_DPG.plot_fitness()  # Use the stored model's fitness data\n",
    "        ]\n",
    "        \n",
    "        # Store visualizations in the replication object\n",
    "        replication_viz['visualizations'] = replication_visualizations\n",
    "    \n",
    "    # Generate combination-level visualizations (PCA and Pairwise)\n",
    "    # Extract all counterfactuals for this combination\n",
    "    counterfactuals_list = [rep['counterfactual'] for rep in combination_viz['replication']]\n",
    "    cf_features_df = pd.DataFrame(counterfactuals_list)\n",
    "    \n",
    "    combination_viz['pairwise'] = plot_pairwise_with_counterfactual_df(MODEL, IRIS_FEATURES, IRIS_LABELS, ORIGINAL_SAMPLE, cf_features_df)\n",
    "    combination_viz['pca'] = plot_pca_with_counterfactuals(MODEL, pd.DataFrame(IRIS_FEATURES), IRIS_LABELS, ORIGINAL_SAMPLE, cf_features_df)\n",
    "\n",
    "# Save visualizations (plots as figure objects)\n",
    "viz_filepath = os.path.join(OUTPUT_DIR, f\"sample_{SAMPLE_ID}_after_viz_generation.pkl\")\n",
    "with open(viz_filepath, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'sample_id': SAMPLE_ID,\n",
    "        'visualizations': visualizations,\n",
    "        'original_sample': ORIGINAL_SAMPLE,\n",
    "        'features_names': FEATURES_NAMES,\n",
    "        'target_class': TARGET_CLASS\n",
    "    }, f)\n",
    "print(f\"\\nSaved visualization data to {viz_filepath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create progress widget for metrics generation\n",
    "metrics_progress_widget = IntProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(visualizations),\n",
    "    description='Metrics:',\n",
    "    bar_style='info',\n",
    "    orientation='horizontal',\n",
    "    layout=Layout(width='500px')\n",
    ")\n",
    "\n",
    "metrics_progress_text = HTML(value='<b>Progress: 0 / ' + str(len(visualizations)) + '</b>')\n",
    "metrics_progress_container = HBox([metrics_progress_widget, metrics_progress_text], layout=Layout(width='100%', padding='10px'))\n",
    "\n",
    "# Display the fixed progress widget and scrolling output area\n",
    "display(metrics_progress_container)\n",
    "\n",
    "# Iterate over all combinations and generate metrics/explainers\n",
    "for combination_idx, combination_viz in enumerate(visualizations):\n",
    "    # Update progress widget\n",
    "    metrics_progress_widget.value = combination_idx + 1\n",
    "    metrics_progress_text.value = f'<b>Progress: {combination_idx + 1} / {len(visualizations)}</b>'\n",
    "    \n",
    "    dict_non_actionable = dict(zip(FEATURES_NAMES, combination_viz['label']))\n",
    "\n",
    "    # Generate metrics for each replication\n",
    "    for replication_idx, replication_viz in enumerate(combination_viz['replication']):\n",
    "        counterfactual = replication_viz['counterfactual']\n",
    "        COUNTERFACTUAL_DPG = replication_viz['cf_model']\n",
    "        \n",
    "        EXPLAINER = CounterFactualExplainer(COUNTERFACTUAL_DPG, ORIGINAL_SAMPLE, counterfactual, TARGET_CLASS)\n",
    "        \n",
    "        # Store explanations as key-value pairs (dictionary)\n",
    "        replication_viz['explanations'] = {\n",
    "            'Feature Modifications': EXPLAINER.explain_feature_modifications(),\n",
    "            'Constraints Respect': EXPLAINER.check_constraints_respect(),\n",
    "            'Stopping Criteria': EXPLAINER.explain_stopping_criteria(),\n",
    "            'Final Results': EXPLAINER.summarize_final_results()\n",
    "        }\n",
    "\n",
    "# Save complete visualizations data with all explanations\n",
    "save_visualizations_data(SAMPLE_ID, visualizations, ORIGINAL_SAMPLE, CONSTRAINTS, FEATURES_NAMES, TARGET_CLASS)\n",
    "print(f\"\\nAll data for sample {SAMPLE_ID} has been saved to disk.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
